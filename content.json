[{"title":"心情 2018.2.22","date":"2018-02-22T12:39:03.000Z","path":"2018/02/22/心情-2018-02-22/","text":"大年初七，在普莲路家中朝北的屋子里望着漆黑月色，听着窗外淅淅雨滴此时心情是平淡的，没有一点涟漪但思路是清晰的，正如已然张满帆的船只 上次写的心情是在元旦前后，至今已快有两月经历上学期末尾的疯狂工作一个多月也经历过年的这段时间的尽情玩耍如今，假期余额不足，是啊，快要开学了开学的信号是LLS在初五晚上的一条微信这两天为此事甚为反感也许是在家放松的心态还未收回也许是因为实在催的很紧，一天多条信息也许是因为这事其实跟我毕业关系甚微 最近一段时间，是在潜意识中不断告诫自己为成为精致利己主义者而奋斗达则兼济天下，穷则独善其身修身齐家方能平天下为自己活出更精彩，需要转变心态 快到而立之年，看到身边的人或有成绩或已平淡悸动的心越发按捺不住然而，如今更需要缄默寡言，更需多思考对做的每次选择进行思考对说的每句话进行思考然后少关心不该关心的事情多主动逮住利于己的一些机会为自己的明天增添筹码 下周就要真正回到学校去年的下半年经历自己觉得充实的半年然而如果以收获论成败，实则仍是平淡新学期，新一年，需要有更清晰的目标，更多的付出该考的托福需保证学习时间，尽力考出好成绩该出的论文，需要尽心尽力去做，保证毕业条件，争取奖学金该找的对象也需要分心去做，但而切莫为没有结果的事情浪费光阴该锻炼的还需锻炼，保证好身体很关键减少为别人的看法所左右，活出自己想象中的样子对形式的东西，尽量用最少的精力去敷衍对要紧的东西，尽量用120分的努力去做好多尝试自己没尝试的东西，不要总活在温暖的港湾里收拾好人际关系，该用心维持的和不该费时间的需要清楚最后，希望每一天都活得精彩，不给自己遗憾，加油！","comments":true,"tags":[{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"},{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"}]},{"title":"心情 2017.12.31","date":"2017-12-31T04:49:31.000Z","path":"2017/12/31/心情-2017-12-31/","text":"午后的实验室，阳光从窗外照进来实验室里人丁寥寥，节日的气氛并不在此泛滥面对着熟悉的屏幕，敲打着字，思绪任意闲逛 不知道到是谁先想出了时间的概念岁岁年年人不同，大概就是最大的时间特征了吧每一年的年末都在进行不断的回忆也在憧憬下一年的光景朋友圈都在晒的18岁的样子眼神中充满着朝气又有多少人对照着自己目前的状态能够不叹息呢 感叹自己已经奔向30岁的年纪三十而立，早已没有时间资本来挥霍对自己而言，很多事情不应该在继续考虑，而是要努力去落实30岁之前，以学为主，不考虑过多的得失30岁之后，需要对自己锱铢必较了吧 知乎上所谓的精致利己主义者备受批判然而在生物发展规律上，优胜劣汰的准则始终贯彻着不以自我更好生存为目的的生物注定被淘汰在大是大非上，有清楚的判断在个人利益上，能够最大限度去获取需要自己用下半辈子的时间去践行 感情是非谁与对与wpq之间实际上是些许瓜葛当断未能断去，徒生纠结那段记忆永远去封存吧，但愿不再忆起来从生理、心理上，自己需要尽快找个伴了，以功利为目的 真正的成熟起来应该是做一名无破绽的伪装者不轻易倾泻自己的真实想法正确处理所有的人际关系少以感情用事，所有的感情都会在时间冲淡要想活得精彩，什么该做什么不该做，心中需要有一杆秤只要去做就认真做，做出成绩，显示出自己的本事做不好得过且过是对自己的敷衍，还不如早点不做不做无意义之事，对自己的时间负责 最后，也说下新年愿望吧早睡早起，多多运动，注意养生科研多产paper，英语托福过95@新女友，欢迎早点来到我的生活","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.10.23","date":"2017-10-23T00:53:19.000Z","path":"2017/10/23/心情-2017-10-23/","text":"生活本身没有太多色彩所以需要你的情趣来点缀生活欢乐的心情不一定能带来成功但欢乐可以带来幸运的美好 过完开学的准备期经历计划很久的西藏之行平淡的博士生活正式开启然而，在这一个多月的生活里并不感到充实，没有做多少事情有时候人需要不断的暗示自己只是为了让自己少做一些无意义的事 博士班的支书让我得去参加党骨班上周的面试又让我深刻体验到面试的紧张人如何才能避免上台/面试过度紧张需要练！需要练！需要多练！ 本来买的球鞋因为十九大的召开而拖延到货本来预期的每天锻炼/跑步因为各种事情而耽搁很多情况，很多事情并不能总是按照自己的预期进行古人云，取乎其上，得乎其中，取乎其中，得乎其下需要对自己多规划，多安排 上周跟咔咔阔别重逢一年多的时间并没有产生太多的生疏感我们有着天生的默契，就能好好说话保持着略微微妙的关系，也许正是最舒适的大家都过得好，那就可以了 最近的研究方向基本确定在自动驾驶交叉口通行策略但对于具体策略的研究，虽然想了很多，但没有成型的理论尝试编程实现，却也走了很多弯路但是，失败不可怕，从失败中收获经验才是最宝贵的接下来希望利用好两三周时间，尽快出点东西赶在年前能写一篇文章投出去，对自己这半年才有个交代12月底的IEEE特刊，是一个不错的机会，希望自己的抓住机会加油！fight！精彩需要动脑思考，需要双手创造！知识需要主动学习，时间需要尽力去争取！OVER！","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"天上西藏 大美于行","date":"2017-10-15T02:16:45.000Z","path":"2017/10/15/西藏之行-201710/","text":"关于这次的西藏之行，想法主要是由小赖从去年就提起的虽然历经一年的筹划，但真正的准备其实很仓促的我，小赖，宇神，增广，四人结伴出行尽管困难重重，但总算得上一次印象深刻的旅行广袤土地，皑皑雪山，佛教文化，风俗人情天上西藏，大美于行！ 无奈天价机票，经过几番艰辛的抢票，才抢到了往返火车票本以为的遗憾之事是需要在西宁耽搁一天但西宁一下火车，我们就直奔二郎剑青海湖景区青海湖比天还蓝的湖水让人无比陶醉美丽的湖边风光，引诱我们流连忘返在傍晚的青海湖畔骑着自行车，别有一番滋味青海湖的景色真是一幅天然、不加修饰的画卷青海湖纪念石青海湖畔青海湖二号码头青海湖骑行 短暂停留，也等来了增广，四人会合就向拉萨进发沿途草原、群山、青稞、牦牛、绵羊比比皆是，不一样的高原风光青藏铁路号称天路，一是沿途风光好，二是确实海拔高火车是在半夜翻越唐古拉山，5000多米的高峰引发些许高原反应的头疼从此以后，在西藏的日子里，每天都会在半夜中醒来 增广的弟弟是在拉萨工作的，他帮我们订好宾馆又带着我们到处去逛第一天到拉萨就到了布达拉宫、大昭市附近逛，还去邮局买了明信片恢弘壮丽的布达拉宫令人震撼，此行没能进去游览是最大的遗憾逛完拉萨市中心，我们去了有特色的小店品尝藏面和甜茶，味道都很不错布达拉宫布达拉宫布宫外围转经筒八廓街藏面和甜茶 我们下一个行程就是重头戏珠峰大本营，但此行充满波折我们在布宫附近报了旅行团，每个人1050的团费，四天三夜但是却遭遇谎称塌方、旅行车超员等状况，不得不因此耽搁一天在拉萨此后，我们去游览了位于拉萨北边的色拉市第一次切身感受藏传佛教和虔诚的佛教信徒，全程我是以旁观者心态来看待的在色拉市见到了传说中的辩经，僧人们两两讨论，或高声，或拍手，或嬉笑，印象深刻为了准备珠峰的行程，我们在第二天就早早回去休整了色拉市大殿之一僧人辩经 第三天我们终于踏上了去珠峰的行程一大早在边防大厦集合办边防证，到了中午左右才出发珠峰的行程大部分时间都在大巴上沿途我们游览了羊卓雍错、卡若拉冰川等景色圣洁的羊湖是西藏三大圣湖之一，神圣而又具有神秘色彩从山上望去，青蓝色的湖面宛如一大块蓝宝石，在云彩阴影下颜色随时间转换在山脚下，我们近距离游览湖边风光，用“圣水”洗涤双手、额头和舌尖，感受上天的给予大美羊湖羊湖美景卡若拉冰川 沿途旅程的颠簸，让最向往珠峰的增广萌生退意，于是他就留在了日喀则从到西藏之后我就一直感冒不停，吃药不停，后来宇神也加入了感冒行列在网上看到太多关于高原反应和感冒咳嗽致死的消息，也让我们犹豫不前直到珠峰行程的第二天凌晨，我才决定好，一定要上去，此生才无憾除了增广之外，我们三人带着导游忽悠买的氧气罐、睡袋、军大衣跟团上了珠峰在重重的边境安检的耽搁、颠簸蜿蜒山路的折磨之后，我们终于到了珠穆朗玛峰国家公园汽车不断前行，我的内心异常激动起来，当第一次看到珠峰的时候我就知道此行绝对无憾我们赶在夕阳下山之前到了大本营，感受了两三分钟的日照金山的壮丽景色，令人震撼在珠峰大本营的夜里是煎熬的，十几个人挤在小小的帐篷里，嘴里咬着氧气导管睡觉大半夜醒来之后，穿着军大衣，带着冬帽，顶着凛冽寒风，在帐篷外感受夜色由于恰好是中秋之夜，月亮格外明亮，很大程度掩盖了传说中的美丽星空第二天清早，在太阳起来之前我们就踏上了返程珠峰旅途山路最美大道318珠峰公园珠峰大本营珠峰帐篷大本营碑石 回到日喀则市，我们在导游的带领下去游览扎什伦布寺，这是藏传八大圣寺，班禅大师主寺扎寺是典型的后藏寺庙，没有前藏的喧嚣，更多的纯粹的信仰精神，供奉了历代班禅灵位导游是风趣的四川小哥，一路上给我们讲述很多关于藏传佛教的东西例如，达赖是观音大士化身，班禅是无量神佛化身白代表观音的慈悲，黑代表金刚佛的力量，红色代表文殊的智慧，黄色则是因为达赖和班禅都隶属黄教珠峰之行的最后是游览沿途的雅鲁藏布江的风光四天的行程令人疲惫，又充满意义，此生也许只有这一行，但值得永远怀念扎什伦布寺 我们尽力去用剩下的有限时间充分感受拉萨的风情，品尝藏式的牦牛肉、酥油茶并在晚上去感受了布达拉宫的夜景，看到了很多拍婚纱照的新人们在天上西藏邮局，我将写好的九张明信片尽数寄出，又买了些特色纪念品最后的上午我们参观了大昭市，景仰了释迦摩尼的十二岁等身佛像在七号的下午，我们踏上了返回北京的列车再见了，西藏，再见了，高原美景布宫夜景大昭市给自己的信","comments":true,"tags":[{"name":"游记","slug":"游记","permalink":"http://yoursite.com/tags/游记/"}]},{"title":"心情 2017.9.23","date":"2017-09-23T11:50:29.000Z","path":"2017/09/23/心情-2017-9-23/","text":"秋分时节，北京的天早晚已有凉意秉承工作的习惯，7点左右起床明天睁开眼能看到操场上晨跑的人儿活力与朝气，觉得这才是学校应有的气息 alert(\"正确\"); if(\"12345678\"==prompt(\"请输入密码\")) { alert(\"正确\"); } else { alert(\"错误\"); location=\"http://blog.laphets.com\"; #返回网站，请自定义 } 从家里启程前的几天骤感风寒一个感冒底子带到北京结果些许天的调养，本已有好转一次晚间的游泳，亦或是晚上踢了被子终使得风寒刚去又起北京的天本来就干燥扛着咽炎真是难受昨天本庆幸好了点又因吃了太多葡萄而愈发严重今天买回金银花和罗汉果一块泡水如果还是未有见效，只能去看医生了。。。 从到了学校已有两周时间除去办理些许手续其他时间都在修改在线学习的论文在得到鲁老师允许之后自行投了IEEE-ITS工作总算告了一个段落了 由于交通大数据方向鲁老师已经不做因此，现在面临方向选择的难题在车路协同和自动驾驶中寻找到切入点并不容易有时间看着论文，看着看着就困了这个方向了解实在有限，有点迷茫为了拓宽自己的知识架构自动驾驶方向是我的一个良好选择希望能早日找到自己感兴趣的点做下去 最近一个事情就是换导师的问题以王老师的意思，几个他的新招博士生需转到其他老师名下而我自然是转到鲁老师名下现在很可能就是我变成鲁老师的第一个博士生虽然对我来说，王与鲁都无区别因为读博路子自己早已认识到需要靠自己老师只能阴引路子，大部分工作都是自己在做今天王老师的学生见面会还算成功，多参加有益处 这两天雅丹/景欣/林博/志榕他们来北京开会昨天找我一起逛了下北航校园昔日同事情，甚是怀念比较震撼的还有景欣报考清华博士衷心祝愿她也能够顺利入学，顺利毕业 突然间成了实验室仅次于俊杰师兄的二师兄了在与其他师弟师妹的相处，也是今后的常态在学生越来越多的情况下，更应该做好师兄的带头作用在科研上多多支持他们，共同建设好团队平时也多与他们这些年轻人交流，能保持年轻心态 下周就开始上课了虽然课不多，但可以重温需学生课堂应该是感触良多的这学期的重点是学好三门数学课这时候我就想起了金华一个令我十分钦佩的人那种积极进取的奋斗精神值得我去学习我也要好好加油了好好做上课好好做科研好好学英语好好学交流好好练身体gogogoo！！","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.9.17","date":"2017-09-13T13:51:27.000Z","path":"2017/09/13/心情-2017-9-17/","text":"一段新的生活，从此开始在装备所工作的时候曾经数次构想在家休息的过程中曾觉得离家的迫不及待在学校近一周时间的折折腾腾目前总算是告下一段落了我的博士生涯开始了 在家呆了有十天的时间处理了各种事情，做着很多的准备工作尽管还是没能赶完论文的终稿但一切都还算顺利，完成很多的事情然而到了北京之后还是发现忘带东西好在问题不大，忘带的党关系介绍信很快便寄到了 12号到学校说实话有点匆忙尽管有同学帮忙，但大多还是自己在做整个人混混晕晕的过了一两天适应了糟糕的宿舍熟识了几位班上的同学多次而艰难地将茶叶给了四位老师与多位同学吃饭叙旧帮建山处理出国事务终于的终于，很多事情都告一段落了 我期待的博士生活其实是一段纯粹的生活偏独立的学术，偏独立的生活，也给自己一段长的时间来思考在未来的三四年里，但愿不会更长好好做点学术，拿下学位好好做自己喜欢的事情好好养成一些习惯，为今后的日子铺垫好好思考自己的人生方向不要急功近利，也不要庸庸碌碌一步一个脚印，好好做下去 每天早上迎着清晨的阳光起床在洗漱中清醒自己再去吃早饭然后是上早课，充实自己的知识体系白天剩余的时间都用来看文献，写论文傍晚是个人运动的绝佳时间，喜欢跑步和游泳晚上拿出时间用来学英语，背单词/练听力/做阅读夜深人静时回到宿舍，在kindle的陪伴中入眠生活/吃饭的作息保持规律，不做大改变减少熬夜，保持精力，多接触新东西，多思考 在入学几天里，可以感受到自己心态的变化确实，博士与硕士有太多的不同希望能少点浮躁，多点耐心去做事少点抱怨，多点踏实去做好自己人生数十载，真正能够过好自己的日子的机会很少而现在正是独立思考/塑造自己的好机会不忘初心，坚持就是对自己最好的交代","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.8.28","date":"2017-08-28T03:19:13.000Z","path":"2017/08/28/心情-2017-8-28/","text":"最近不适合说太多话说多了容易感伤有人说容易落泪是因为不够坚强但我觉得是因为比较容易投入感情 想想去年，来时青涩的脸庞怀揣着兴奋和希望，来到这里上班早上踩着阳光上班，晚上迎着路灯回宿舍周末就坐着班车回家，周一来回到单位工作时而轻松，时而激情，时而欢乐，时而彷徨这也许就是一种美好的生活方式 内心深处的些许悸动让人不那么安定静下来想想，有时候人总要有所追求做出选择也许并不是百分百的愿意但是，既然选择就没有后悔既然选择就会向着希望坚持到底 虽然才刚一年半就要离开但我也不曾后悔过每个人的生命都有自己应有的轨迹经历过，欢笑过，收获过，就是值得的我一向是善于记忆的，无论陈年累月之后在这里，遇到的一些些可爱的人儿也许哪天，在梦里，在发呆时，特别是在迷茫时想起你们，会让我觉得有趣，觉得心情欢快 装备所，给过我家的感觉暖暖的，那种感觉不会忘记","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.8.20","date":"2017-08-20T02:55:12.000Z","path":"2017/08/20/心情-2017-8-20/","text":"立秋已过烈日渐渐没有了煞气每天迎着朝阳，踩着马路听着English，走路上班虽然这样的日子已不多但珍惜眼前，才能着眼未来 这段时间本是伤感的离别时但却总弥漫着high的味道聚餐、唱k、玩牌、畅聊年轻的朝气如火，青春好聚好散由高老板带队，尽情狂欢也夹杂着些许关于组里发展的讨论我们的话题太多太多 昨天还和母上与其他阿姨畅玩泉州吃喝、购物，现代人的生活后来去了姐姐的住处东海湾的美景不错虽然累，但也很满足 最近的high也使得睡眠较少身心皆是疲惫不堪昨晚整整睡了11个多小时才有点缓过劲来好好休息，因为我还有很多事要做 下周组长出国，我会待到下下周他回来两个组里ppt要做月底之前要给个北京基金本子给鲁老师一直拖延者的论文，也需要尽快完稿闲暇之余跟松航、圣阳吃顿饭告别在这之后就是迎来自己的新的生活了 金华的为人刚直不阿虽然我不是很合得来但是，他的经历和想法令人触动，需要好好学习坚持学好技术，提升自己为未来的自己多点灿烂而奋斗！","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"}]},{"title":"心情 2017.8.13","date":"2017-08-13T05:36:53.000Z","path":"2017/08/13/心情-2017-8-13/","text":"公历8月中旬，农历仍是闰六月酷暑不减，炎热异常坐在屋里，吹着风扇，冒汗不止临近开学，诸事繁多公事、私事，心情茫然而沉重很多时候想随心所欲地做事却容易受到干扰而偏离本来的目标所幸随着年龄增长，能更清晰地思考 离职倒计时还有3周了虽然自己人在单位但已无限憧憬学校生活组会上领导仍继续地表达他的宏图设想我在下面想着自己的求学之道这里风景虽好但我只是过客些许留恋，但终要向前 本来想着带着两篇文章到学校去结果到现在，第一篇还没有写好目标和实现有时候会有些距离但是没有没有目标的鞭策也许会恍恍惚惚，虚度时间也许现在连第一篇的影子都还没有剩下的时间，就抓紧完成这篇文章了 最近最头疼的事情就属鲁老师布置的基金本子驾驶人行为学习，这是我不熟悉的方向资料查阅，方案设计，内容撰写都很困难特别是，上次提起由我来做车相关的事情这是我特别不愿意的我不想放弃自己三四年来学的东西不想涉足硬件、车辆领域所以，之后还得跟老师好好谈谈 Ti7也结束，该收收心做事了其实最近也还好，基本上时间都投入到了论文撰写了虽然显性的成果不多，但论文一点一点在完善着就是周报不太好写了，毕竟投入的时间并不多单位的事情，就得过且过吧下周需要去买车票，着手办理离职手续了","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.8.8","date":"2017-08-08T00:45:54.000Z","path":"2017/08/08/心情-2017-8-8/","text":"凉风至白露降寒蝉鸣 适逢农历闰年，夏季复六月台风刚过，又是一连酷暑天一叶落而知秋，秋天真的还不来么 前两天高温假期，同学来厦一连两日，游荡于烈日之下皮肤煎烤，汗流浃背在家者羡慕出游者之乐出游者悔恨不如在家歇着 近期任务繁多身在假期，心有忙务终不能好好歇息忙忙碌碌之中，时间过得快应该清楚轻重缓急，合理分配时间精力 那年的初秋，长城上，故宫里，鸟巢中昔日的青涩停留在深深的记忆里刚从中学走出来，踏入北航校园神往而迷茫，昏昏沉沉度过好些年 而今即将迈入而立之年昔日小舟，终成舰艇扬起风帆，重新起航任凭狂风暴雨，波涛汹涌向着目标，不断前行","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.7.30","date":"2017-07-30T04:57:34.000Z","path":"2017/07/30/心情-2017-7-30/","text":"一连几日，台风雨季，乌云密布给干涸的大地带来大量的雨水给酷暑的夏天带来难得的凉爽然而，强降水也带来很多弊端也为受到灾害侵袭的人民表示同情 目前这一周是处在一个较长的年假当中两个双休日加上五天工作日昨天正好去厦门口腔医院拔掉了困扰许久的智齿痛苦会持续几天，吃饭生活也会受到影响但长痛不如短痛，狠心拔了以后就好了 本来这个月要完成的一篇IEEE-ITS的长文因为各种拖延，没能按时完成剩下还有实验和后期的修改没有做想着说假期这段时间尽量做一做也算是给自己一个交待吧，加油 上学的日子越来越近跟学校那边的接触也变得很多这不是什么坏事，能提前感受在校的感觉这一次上学，希望不要跟刚到北航那般迷茫这一次，我需要目标更坚定，意志力更强 长大之后，想的事情变的很多学业、工作、爱情和经济，都是要考虑的之前就提到过，人是社会人，需要上述这些东西每个人都渴望去变得更好机遇也许是天注定的但个人的努力却能逆天改命 远大的目标需要拆分成小目标一步一个脚印去执行每个每天能对自己有个小要求一星期，一个月，一年，十年，一辈子小要求就会积攒成大成就有句话说得好，1万小时的锤炼——是任何人从平凡变成世界级大师的必要条件","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.7.23","date":"2017-07-23T07:04:40.000Z","path":"2017/07/23/心情-2017-7-23/","text":"道理我都懂，但我还是不想去做与其逼迫自己，倒不如顺其自然话虽如此，但需要保持必要的原则弦绷得太紧，很容易断放纵自己久了，也就难以收紧了正所谓张弛有度，最好是略紧的状态 夏日的中午，在家码字上周的周报一塌糊涂，草草提交虽然说是对自己的不负责任，但也许是真的烦最近天气烦，杂事烦，旁人烦，科研烦，心情真的不是那么好憧憬着走遍大山好水，但没有时间也没有经济经常是自己一个人在想事情的多，长大了就是这样子吧 领导一再强调年轻的时候需要奋斗这个道理谁都懂，但奋斗的动力何在却没有人去指引有些时候，鼓舞别人需要站在他人的角度最后剩下一个多月的班，有点儿心不在焉了很多时候，人也是被动的活着而已 想着以后的生活既是兴奋，又是担忧，不免显得有点焦急不断去选择改变，让自己陷入艰难模式只是为了能够使自己变得更好，在苦难中成长等到若干年之后回顾以前的困难，就不觉得什么了 今天的思路很乱，断断续续人为什么要这么复杂为什么不能只关心该关心的人和事为什么不能说想说的做想做的为什么需要考虑别人的感受为什么要思考以后的事情很多的为什么都没有答案因为人已不是人，而是社会人","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"}]},{"title":"心情 2017.7.17","date":"2017-07-17T02:34:09.000Z","path":"2017/07/17/心情-2017-7-17/","text":"当早睡也治愈不了白天困乏的时候也许这是真累了忙碌的生活不代表充实可能只是遭罪但是，忙碌也可能代表自己正在努力不放纵自己，终究会有所收获 最近大部分心思放在搞论文上好不容易整理出来的思路兴奋的感觉，连睡觉都在思考模型内容主题的撰写，模型的推导都差不多之后在数据实验中，又一次有了挫败感也许理论和实际的应用总是隔着一道鸿沟而现在要做的就是搭桥砌好一块块砖石，一点一点把它做下来 人的心思总是善变的，特别是针对其他人今天，我觉得你做这个比较合适明天，我就觉得这个想法有意思，你来试试看这就像是在操作一个木偶，主人是个大艺术家但是，木偶是没有生命的，没有思考，不会厌烦当操纵的是人的时候，有个词叫累觉不爱 最近的事情确实比较多组里需要同时处理两批数据，还要翻译论文写报告还有采购设备的事务，也着实比较烦人然后，我还需要投入大量精力经营自己的论文的确，我是善于抱怨的，我在努力改掉这个坏毛病事情总有轻重缓急，主观性强的话就能够有条理进行处理但愿自己能够越来越成熟起来吧 七月的天，还是那么热，无论南北每天踩着朝阳上班，晚上拖着疲惫的身子回到宿舍一天的充实感不多，毕竟罗马不是一日建成的年轻人在迷茫的时候，要选择艰难的路子不要让自己一直处在舒适区，总是需要持之以恒的努力","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.7.9","date":"2017-07-09T00:48:03.000Z","path":"2017/07/09/心情-2017-7-9/","text":"I am not a supermanI cannot save the worldwhat I want to do is thattrying my best and working hardto make something diferenceto change myself to a better oneto bring warmth to someone who love meI will bear the sweat and thornsI will keep walking to the end 上周无大事，过得很快驾驶证寄到了，十年期，很长一段时间不用换了报道事情已开始，加入新生群，一切都像原来的的样子组里的数据处理工作还在继续，进展不大，兴趣不大来实习的北京小孩回去了，办理签证手续，据说还会回来连续两周回老家吃鸡肉、鸭肉、鹅肉，有点腻小事就这么多，没了 不大不小的事情，就是一直在做的在去年面试那会，曾经跟鲁老师说过要准备两篇论文到现在还没有影呢，留给我的时间只有两个月了平均下来，一个月要出一篇，时间很紧张思路整理、框架撰写、数据实验、查缺补漏所以，这段时间我会一直在写论文这一年来在这边的收获也就只从这两篇论文看得出了有点东西再出发，也会给自己多点自信 现在在听的歌：《Because you live》","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.7.2","date":"2017-07-02T05:59:16.000Z","path":"2017/07/02/心情-2017-7-2/","text":"夏日，艳阳，微风，蝉鸣午后，风扇，寂静，人倦七月如火，南方的夏天潮湿多汗对着电脑，码着字，思绪轻飘飘地 这周收到了纸质版通知书感受着家人们的喜悦心情自己躁动的心泛着些许平静也许因是结果早已知晓也许是感受着即将来到的压力只盼日子越将来临，心中越是坦然更好 鲁老师给吩咐审理国内会议的稿件数量虽多，但质量参差不齐，费点时间而已不巧正当此时，组里事务较多，有点烦躁几批数据下来， 没有太多背景知识盲目分析，令人可笑，领导的急迫心态尤其滑稽想着既要在临走之前同时准备这里和以后的两篇论文深感无力，但有不得不激励自己向前，咬咬牙就好了 品志也本科毕业了他这些年的成长令人欣喜有过于年龄的老成和心态回家同时准备着考研和考公有心人，天不负，终究能有个好结果的 相比而言，某位在京某所的询问者师兄长师兄短的问候，态度可以然后业务能力与所见的认真程度的反差让人不免叹息，女生就是不适合科研 心情浮躁，需要用做事去夯实该学学，该玩玩，不要过多胡思乱想走好自己该走的路就好了好了，不说了","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"辛普森悖论及贝叶斯解释","date":"2017-06-26T00:44:11.000Z","path":"2017/06/26/辛普森悖论及贝叶斯解释/","text":"辛普森悖论（Simpson’s Paradox）亦有人译为辛普森诡论，为英国统计学家E.H.辛普森（E.H.Simpson）于1951年提出的悖论，即在某个条件下的两组数据，分别讨论时都会满足某种性质，可是一旦合并考虑，却可能导致相反的结论。(from 百度百科)关于辛普森悖论的统计学解释是贝叶斯置信网络在因果推论中的重要应用。 1 问题描述考虑一个关于疾病用药的病人恢复情况的医学实验。两组实验分别在40个男性和40个女性中进行。实验数据如下所示： 实验探究的问题是：药物是否会提高病人的康复机率？根据第一个表格中的男性实验结果，服用药物和未服用药物的康复机率分别为60%和70%在第二个表格中的女性实验结果中，服用药物和未服用药物的康复机率分别为20%和30%。因此，从两组不同性别的分别实验可以看出，服用药物的康复机率更小。然而，如果不考虑性别信息，综合两组实验数据得到第三个表，服用药物和未服用药物的康复机率分别为50%和40%，由此得到与上面两组实验矛盾的结论，服用药物有助于疾病康复。这就是辛普森悖论的一个典型例子。 2 贝叶斯解释统计学的观测证据（observation evidence）和介入证据（interventional evidence）往往是不同的，对于设计药物（D）对疾病恢复（R）的因果推论，用条件概率表示应该是$P(R|D)$，而如果增加性别因素（G），条件概率为$P(R|G,D)$，二者是不同的概念。 （1） 不考虑性别的影响的话，可以得到 $$P(R|D)=\\frac{\\sum_G{P(R|G,D)P(G)P(D)}}{\\sum_G{P(D)P(G)}}=\\sum_G{P(R|G,D)P(G)}$$服用药物D=1，未服用D=0，带入表格数据有：$$P(R|D=1)=0.6\\times 0.5+0.2\\times 0.5=0.4$$$$P(R|D=0)=0.7\\times 0.5+0.3\\times 0.5=0.5$$因此，服用药物的恢复机率是减小的的。 （2）考虑性别的影响的话，以男性G=1，女性G=0，由表中数据可以直接得到$$P(R|G=1,D=1)=0.6$$$$P(R|G=1,D=0)=0.7$$$$P(R|G=0,D=1)=0.2$$$$P(R|G=0,D=0)=0.3$$因此，不管服用药物与否男性恢复机率都大于女性。 （3）引入无关影响因素$P(D|G)$$P(D|G)$是指不同性别的服用药物比例，这个数值大小对于比较药物对疾病作用，还是药物对性别作用都是无关变量。实际上，第三个表格中的联合计算方式是由以下公式得到的：$$P(R|D)=\\frac{\\sum_G{P(R,G,D)P(G)}}{P(D)}=\\frac{\\sum_G{P(R|D,G)P(D|G)P(G)}}{P(D)}$$这样做的话就违背了分层抽样原则，探究药物对疾病恢复机率的影响，如果按照性别不同分层，而对于每个分层里面应该进行随机抽样，即服用药物和未服用药物的人数应该一致。考虑不同性别对恢复机率的影响，男性的恢复机率（服药与未服药人数相同时）为$$P(R|G=1)=0.5\\times(0.6+0.7)=0.65$$女性恢复机率（服药与未服药人数相同时）为：$$P(R|G=1)=0.5\\times(0.2+0.3)=0.25$$由此可见，在不考虑药物作用下，男性的恢复机率远高于女性。而题干中的男性和女性分别为3:1和1:3的不同服用药物人数比例，直接导致了服药样本中高恢复机率的男性较多，低恢复机率的女性较少，而未服药样本反之，二者取样并不均匀，因此，由性别带来的取样差异性导致了错误的实验结论。 总结综上，辛普森悖论产生的原因来自于抽样调查时违背了抽样对象的随机性原则，使得与实验结论不相关的变量影响到了实验结果。在现实生活中，“统计平均陷阱”是辛普森悖论的一个重要表现形式。例如全国城市房价同比涨跌幅度，由于城市发展程度不同，各个城市房价不同，随着城市化进程加快，中小城市的房产交易规模扩增速度高于大城市，所以就会出现这样的情况：全国各个城市的房价都在增长，而房价均值同比却在下降。原因是由于中小城市的低价房产同比交易量高于大城市的高价房产同比交易量，所以全国总体房价的均值就被拉低了。","comments":true,"tags":[{"name":"统计学习","slug":"统计学习","permalink":"http://yoursite.com/tags/统计学习/"}]},{"title":"心情 2017.6.25","date":"2017-06-25T01:26:53.000Z","path":"2017/06/25/心情-2017-6-25/","text":"人们常说，天下没有不散的宴席现代人一辈子会有很多次聚聚离离每个人心中都有自己的诗和远方每一次的欢乐会成为一段美好的记忆每一回的苦楚会成为一个有用的经验教训而我们，时刻在前行着，谁也不能停下自己的脚步 上周，学校那边来了消息通知书将于下周以EMS方式寄出正式的文件会有一种格外踏实的感觉而我也需要渐渐谋划着自己该过的日子离别纵然很伤感，因为万分不舍但心中的期盼是不断前行的动力 最近在看关于贝叶斯理论的书，有点头大贝叶斯理论是一门有趣的学问，可以赖以吃饭的工具贝叶斯既能将实际经验和统计结合又可以解释一些现实中直观理解有误的“悖论”“辛普森悖论”就是一个很有趣的现象贝叶斯理论是现代统计一大流派通过机理和统计结合的建模方式将是我未来研究方向 周四的所里3V3篮球赛十分享受好久的阴雨天，好不容易等到天晴一次酣畅淋漓的篮球比赛，连打3场尽管出场时间不多，但汗水和激情不会说谎无论走到哪里，无论身在何方有志同道合的人一块做喜欢的事情，足矣","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.6.18","date":"2017-06-18T01:33:31.000Z","path":"2017/06/18/心情-2017-6-18/","text":"夏至将至，夏雨不断不觉得，雨已下了一周时间灰蒙蒙的天气笼罩着潮湿的大地清凉的夜晚，睡觉时不免需要多盖被子稀稀落落的雨打声也是点缀着万般宁静的生活 上周佳哥因公出差来厦门几天由于恰好不在周末时间，没法前往一聚在电话中聊了接近两个小时自从认识佳哥开始，佳哥便展示出了超乎一岁的成熟在读博之路上，略显坎坷，更显出其话语的沧桑感每个人的前进道路上都不会是一帆风顺些许的颠簸只会锤炼我们面对困难的意志力佳哥的想法还是很多的，多与其交流裨益颇丰 因听他们聊起过建山在博二要出去交流的消息周五晚上回家路上给建山打了电话聊聊近况山神一贯的自我逍遥的生活，正在操场散步呢建山申请到了要去英国交流的机会，国家资助也下来了但聊起签证问题，由于雅思过期，不能正常申请学生签建山向来小心、谨慎而又低调，相信这些小事都不是事儿山哥的过人之处就在于超强的自我约束力和不绝的动力山神的高度，值得我辈们敬仰、效仿（to佳哥：向高人多学习） 也是周五晚上，本在趁着618电商活动给家里置办些生活用品赖博来电话畅聊人生，赖博还是有意思啊博士生活总会有单调烦闷的时候，也是必经的历程做科研的枯燥和内心的躁动，常常会令人压抑，需要释放赖神其实也算是心胸阔达之人了，但却也难免有些彷徨都说孤独是成功最好的伴侣，没有克服内心难以成大事但也有潇洒生活的范例，如岳师兄、刘洋师兄他们，寓乐于学小赖提起国庆的西藏的洗礼之行，叫上我和宇神、增广等人一次不一样的旅行，也许能给予我们不一样的人生感悟，也好 不知不觉，一周里与本科在校读博的仅有三位同学都有了交流也许他们正是以一种格外亲切的方式来欢迎我的归来历经多年同窗，而又恰巧深处同样境地，此中情谊难以言语可爱的学校、可爱的人儿，正向我挥手，招唤我的前来我正以一种八年前的期待的心态，想象着再次来到学校的生活也许这次，心态不一样了吧，多了点准备，少了点慌乱过着自己想过的生活方式，就是人生中最大的快乐愿意去付出，也期待收获，让自己觉得有意义，而不会感到在虚度天行道，君子以自强不息；地势坤，君子以厚德载我顺应天时，也把握机会，能动地创造自己的生活，这就是我的世界观","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.6.12","date":"2017-06-12T00:37:12.000Z","path":"2017/06/12/心情-2017-6-12/","text":"臧克家的《有的人》这样描述：“有的人活着，他已经死了有的人死了，他还活着骑在别人头上活着，很多人巴不得他早点死为了其他人更好地活着而死，则会让人铭记但是，还有第三种人，他活着，大家并不知道或因没有追求，或因没有努力，实在没必要去讨论 毛主席在《纪念白求恩》中说过：“一个人能力有大小，但只要有这点精神，就是一个高尚的人，一个纯粹的人，一个有道德的人，一个脱离了低级趣味的人，一个有益于人民的人” 每个人活着都有着不一样的意义有些人为钱而活，视财如命，如葛朗台有些人为权而活，野心昭然，如朱棣有些人为色而活，安于享乐，如秦二世钱权色之利的追逐是最最真实的人类，来源于动物本能但也有些人不太一样，活着不为自己的利益革命年代，多少烈士视人民、国家利益高于生命有丁汝昌、邓世昌、黄继光、董存瑞等 经济学上说，商品的价值取决于社会必要劳动时间而一个人的价值在于创造了多少商品价值，能顶几个人美国海军次长Dan Kimball说钱学森能顶3~5个师关于这个价值的判断方式是十分功利的，也是片面的梵高死之前，他的画作一文不值，但现在价值连城过了这么多年，他所做的事情就没人能替代？当然不是所以经济学的价值判断，并不完全适用 人类社会就像是一台大机器，人类文明多次的社会革命就像是在给机器换动力而在大革命之外，机器还需要日常维持运转现代人都是社会人，社会人就享受了这个大机器创造的产品为了高效生产，每个人都应该尽力去改进这个机器大机器越来越大，也越复杂，每个人工种分工更明确有些人负责零件设计，有些人负责拧螺丝但是呢，因为分工差异，每个人分到的财富就不均等按劳分配、按需分配都是初级社会的产物，只是字面上的公平而已 漩涡鸣人所追求的是得到木叶村里的人的认可发表SCI期刊论文，很多学者初衷仅是所研究的东西被人认可受认可用流行的语言讲，也就是点赞这逐渐成为广泛意义上的价值评判指标人们通过互动的方式告知于其他人所做之事的价值与否这个指标也是常说的与“利”相对的“名” 习总书记说，年轻人要立志做大事成大事者，终将被历史铭记，千古传诵其伟绩成大事者，然而，也有默默无闻，甘为孺子牛人生的意义不在于享受名利，而在于奉献自己名利只在于奉献的过程顺手摘得罢了，不是目的不过，在奉献过程中，很多人于迷失自我，找不着正确的方向所以名利的作用，也是在于能够适时地给予激励 用数学的观点看，逐名利者和奉献者的价值函数各有不同名利和奉献曲线正负相关性交错，但总趋势是螺旋式上升的逐名利者往往由于贪婪特性陷入名利局部最优，原地踏步只为奉献者，往往由于缺少名利方向指引，丧失动力所以，只有奉献为主，名利为辅的人，才能真正地不断往前走实际上，奉献和名利是辩证存在的， 既矛盾又统一真正善于把握二者之度的人，能灵活运之，大概就是所谓大彻大悟了吧","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"高斯过程回归（Gaussian Process Regression）","date":"2017-06-09T01:00:59.000Z","path":"2017/06/09/高斯过程回归（Gaussian-Process-Regression）/","text":"在概率论和统计学中，高斯过程是指观测发生在连续域（例如：时域、空间域）中的一种特殊的概率模型 1 基本概念在高斯过程，连续的输入空间的任何点与正态分布的随机变量相关，而且任何随机变量的有限集合满足多重正态分布，例如变量间的任意线性组合是正态分布，高斯过程分布是所有随机变量在连续域中的联合分布在机器学习理论中，针对于推广训练数据（generalize train data）的算法，如果学习方法在对系统发出请求之前进行，称为急切学习（eager learning），如果学习方法滞后于对系统的请求，称为懒惰学习（lazing learning），K近邻算法就是典型的懒惰学习方法懒惰学习方法一般模型可移植性强，适用于不同的问题域，但要求较大空间来实时保存训练数据集，因为缺少对数据集合的抽象而使得预测过程计算量大。懒惰分类器适用于数据集的特征较少的情况因此，从机器学习算法的观点看，高斯过程采用懒惰学习的方式来度量样本间的相似度（核函数），从而基于训练数据预测位置观测输入的结果。预测结果往往是边缘分布（多个概率分布函数的累加）函数空间视角（function-space view）：高斯过程可以看作是基于多个函数定义分布，并在函数空间做推断分析 2 问题描述对于给定数据集$D_N=\\{\\mathbf{x}_n,y_n\\}_{n=1}^N$，其中$\\mathbf{x}_n\\in \\Re^m$，令$X=[\\mathbf{x}_1,…,\\mathbf{x}_N]^T$作为观测输入数据矩阵，即输入空间；$Y=[y_1,\\dots,y_N]^T$作为观测输出向量，即输出空间。考虑非线性映射$\\phi(\\mathbf{x}):\\mathbf{x}\\in \\Re^m \\rightarrow F$，这个映射可能是未知的也可能是无限维的。核函数$k(\\mathbf{x}_i,\\mathbf{x}_j)$可以满足这个特性，核函数用内积形式来构建特征空间F为：$$k(\\mathbf{x}_i,\\mathbf{x}_j)=&lt;\\phi(\\mathbf{x}_i),\\phi(\\mathbf{x}_j)&gt;$$典型的核函数包括径向基函数$k(\\mathbf{x}_i,\\mathbf{x}_j)=\\exp(-\\Vert\\mathbf{x}_i-\\mathbf{x}_j\\Vert^2/2\\rho^2)$，其中$\\rho&gt;0$是宽度参数定义高斯分布$N(\\mu,\\Sigma)$，其中$\\mu$是均值，$\\Sigma$是协方差在高斯回归过程模型（Gaussian process regression，GPR）中，每个样本$y_n$可以表示为：$$y=f(\\mathbf{x})+\\varepsilon$$其中$f$是零均值高斯过程$\\mathbf{f}\\sim N(\\mathbf{0},K_{XX})$，$K_{XX}=\\{k(\\mathbf{x}_i,\\mathbf{x}_j)\\}\\in \\Re^{N \\times N}$是核函数定义的特定协方差矩阵，$\\varepsilon \\sim N(0,\\sigma^2)$定义$\\mathbf{K}_{X\\mathbf{x}}=[k(\\mathbf{x}_1,\\mathbf{x}),\\dots,k(\\mathbf{x}_N,\\mathbf{x})]^T\\in \\Re^N$典型的高斯过程回归方法是为了对于任意测试数据$\\mathbf{x}^*\\in X$估计预测分布$p(y|\\mathbf{x}^*)$，基于高斯概率假设，可以得到条件分布：$$\\hat{p}(y|\\mathbf{x}^*,X,Y)\\sim N(f(\\mathbf{x}^*),g(\\mathbf{x}^*))$$这里，$$f(\\mathbf{x}^*)=\\mathbf{K}_{X\\mathbf{x}^*}^T(K_{XX}+\\sigma^2\\mathbf{I})^{-1} Y$$$$g(\\mathbf{x}^*)=\\sigma^2+k(\\mathbf{x}^*,\\mathbf{x}^*)-\\mathbf{k}_{X\\mathbf{x}^*}^T(K_{XX}+\\sigma^2\\mathbf{I})^{-1}\\mathbf{k}_{X\\mathbf{x}^*}$$其中$\\mathbf{I}$是相应规模的单位矩阵特别地，令$\\mathbf{a}=[a_1,\\dots,a_N]^T=(K_{XX}+\\sigma^2\\mathbf{I})^{-1} Y$。因此$f(\\mathbf{x}^*)=\\mathbf{a}^T\\mathbf{k}_{X\\mathbf{x}^*}=\\sum_{i=1}^N a_ik(\\mathbf{x}_i,\\mathbf{x}^*)$由此可见，高斯过程可以用一系列的基函数组合来表示 3 高斯过程模型估计在高斯模型估计中，噪声方差往往视为一个参数，并于核函数在在一起，即$\\sigma$常用的模型参数估计方法是边际概率$p(Y|X)$，可以通过条件概率和先验的乘积积分来表示，即为$$p(Y|X)=\\int p(Y|\\mathbf{f},X)p(\\mathbf{f}|X)d\\mathbf{f}$$边际概率取对数有：$$J^{ML}=\\log p(Y|X)=-\\frac{1}{2}Y^T(\\mathbf{K}_{XX}+\\sigma^2\\mathbf{I})^{-1}Y-\\frac{1}{2}\\log \\det(\\mathbf{K}_{XX}+\\sigma^2\\mathbf{I})-\\frac{N}{2}\\log(2\\pi)$$或者，考虑输出概率密度函数和高斯过程回归估计之间的Kullbak-Leibler（K-L）散度作为代价函数，即有$$KL=\\int p(y)\\log\\frac{p(y)}{\\hat{p}(y|X,Y)}dy=\\int p(y)\\log p(y)dy-\\int\\log\\hat{p}(y|X,Y)p(y)dy$$其中上式第二项$R=\\int\\log\\hat{p}(y|X,Y)p(y)dy\\approx E(\\log\\hat{p}(y|X,Y))求最大值$.由于$$\\hat{p}(y|X,Y)=\\int \\hat{p}(y|\\mathbf{x},X,Y)p(\\mathbf{x})d(\\mathbf{x})=E(\\hat{p}(y|\\mathbf{x},X,Y))\\approx \\frac{1}{N}\\sum_{j=1}^N \\frac{1}{\\sqrt{2\\pi g(\\mathbf{x}_j)}}\\exp \\left(-\\frac{(y-f(\\mathbf{x}_j))^2}{2g(\\mathbf{x}_j)}\\right)$$因此，将上式带入$R$，并引入$p(\\mathbf{x})$的真实密度，可以得到$$R\\approx J^{KL}=\\frac{1}{N}\\sum_{i=1}^N\\log\\left(\\frac{1}{N}\\sum_{j=1}^N \\frac{1}{\\sqrt{2\\pi g(\\mathbf{x}_j)}}\\exp \\left(-\\frac{(y-f(\\mathbf{x}_j))^2}{2g(\\mathbf{x}_j)}\\right)\\right)=\\frac{1}{N}\\sum_{i=1}^N\\log\\left(\\frac{1}{N}\\sum_{j=1}^Np_{i,j}\\right)$$其中$p_{i,j}=\\frac{1}{\\sqrt{2\\pi g_j}}\\exp\\left(-\\frac{e_{i,j}^2}{2g_j}\\right)$，这里$e_{i,j}=y_i-f_j$，$f_i$和$g_j$分别定义$f(\\mathbf{x}_i)$和$g(\\mathbf{x}_j)$由于真实密度$p(y)$和$p(\\mathbf{x})$并不知道，但不同级别的概率函数可以调整至结晶误差的$N^{-1/2}$阶，所以可以用估计器插值法近似KL散度高斯过程参数估计不管是通过$J^{KL}$还是$J^{ML}$，都是非线性优化任务，需要对$(K_{XX}+\\sigma^2\\mathbf{I})^{-1}$进行迭代，每步计算复杂度是$O(N^3)$ 4 带噪声的离散观测值估计实例根据上面内容，已知有先验分布$y\\sim N(0,K_{XX}+\\sigma^2\\mathbf{I})$，对于任意测试数据$y^*$有：$$\\left[ \\begin{array}{l}y\\\\y^*\\end{array} \\right] \\sim \\left[ \\begin{array}{l}\\mathbf{K}_{XX}+\\sigma^2\\mathbf{I}&amp;\\mathbf{K}_{X\\mathbf{x}}\\\\\\mathbf{K}_{X\\mathbf{x}}^T&amp;\\mathbf{K}_{\\mathbf{x}\\mathbf{x}}\\end{array} \\right]$$其中，$\\mathbf{K}_{\\mathbf{x}\\mathbf{x}}$恒等于1","comments":true,"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"谱聚类（Spectral Clustering）","date":"2017-06-06T07:44:16.000Z","path":"2017/06/06/谱聚类（Spectral-Clustering）/","text":"谱聚类算法是基于标准线性代数求解的，比传统的聚类方法（如K-means）效果好谱聚类的两个关键的数学依据是相似图和图拉普拉斯聚类的目标是将数据集划分成若干组子集，使得组间差异性最大而组内差异性最小 1 图论相关知识用图论的角度思考，将每个数据点视为顶点，而数据点之间的相似性视为边，则可以定义相似图$G=(V,E)$，则聚类问题转化为用最小的代价去划分图，使得不同组间边的连接权值总和尽可能小，而组内边的连接权值总和尽可能大相似图是无向图，可以建立邻接矩阵$W=(w_{ij})_{i,j=1,\\cdot\\cdot\\cdot,n}$，如果$w_{i,j}=0$表示顶点$v_i$和$v_j$之间无连接边，定义顶点的度为$d_i=\\sum_{j=1} ^n w_{ij}$定义不互斥的两个子集A和B有$W(A,B):=\\sum_{i\\in A,j\\in B} w_{ij}$定义$|A|$为A的顶点数，$vol(A)$为A中所有顶点度之和 2 不同的相似图相似图的构建主要依赖于顶点间的相似性或者距离来构建局部数据点的近邻关系，构建方法有：（a）$\\varepsilon$ 近邻图：即设置顶点距离的最大阈值，从而得到稀疏图，适用于无向图（b）$k$近邻图：即设置顶点的最大近邻数，适用于有向图，对于无向图可以分别考虑单向和互近邻两种情况来构建无向图（c）全连接图：采用高斯相似函数$s(x_i,x_j)=\\exp(−\\Vert x_i−x_j \\Vert ^2/(2σ^2))$ 3 图拉普拉斯图拉普拉斯矩阵是谱聚类算法的重点非标注化的图拉普拉斯矩阵定义为$L=D-W$，$D$是顶点度组成的对角阵，$W$是邻接矩阵$L$是对称半正定矩阵，最小的特征值为0将L标准化有：$L_{sym}:=D^{-1/2}LD^{-1/2}=I-D^{-1/2}WD^{-1/2}$，$L_{rw}:=D^{-1}L=I-D^{-1}W$ 4 标准化谱算法流程算法输入：$n$维相似度矩阵$S$，聚类数$k$（a）构建相似图和邻接矩阵$W$（b）计算非标准化拉普拉斯矩阵L（c）计算前$k$个特征值对应的特征向量（d）构建包含$k$个特征向量的矩阵$U\\in R^{n\\times k}$（e）对$U$进行标准化得到$T$，$t_{ij}=u_{ij}/(\\sum_k u_{ik}^2)^{1/2}$（f）对$T$中的特征向量进行聚类，则聚类结果每一行的类别对应最初的邻接图N个顶点的类别 参考文献 Ulrike von Luxburg. A Tutorial on Spectral Clustering. Statistics and Computing, 17 (4), 2007.","comments":true,"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"心情 2017.6.5","date":"2017-06-05T07:51:50.000Z","path":"2017/06/05/心情-2017-6-5/","text":"螳螂生；鹏始鸣；反舌无声。——芒种三候 芒种是南方地区农作物收获的时节有芒的麦子快收，有芒的稻子可种金灿灿的稻田，是阳光和雨露的赠予更是辛勤耕耘者的劳动结晶然则，新的种子也即将播下依然可以憧憬着来日的丰收 六月叩响了盛夏的大门知了的叫声此起披伏夏雨冲洗的清凉让人仿若深秋却也免遭多少烈日的毒害一年一度的高考按期而至为的是检验学子们多年读书的成果同时也是无数人走向大世界的一张船票 人们总是徘徊于各种起点和终点殊不知，人生的旅程是一场无尽的马拉松所谓的终点只不过一块里程碑同时又是下一阶段的起点有些人会流连于自己以往的些许成就驻足于大大小小里程碑而耽搁了时间龟兔赛跑，持之以恒就是赢家 依稀记得那年，茫茫然地通过了高考的洗礼之后在多少夜里为落榜噩梦而惊醒想起来，还是年少经历太少也在多少美梦中憧憬未来的种种美好其实大多只是幻想在未知世界前，不考学习靠空想就是笑话只有胸有成竹才能真正驾驭自己 古人云：一分耕耘一分收获世上路太多，康庄大道也很多认定对方向，不顾虑太多所有的汗水都会结晶成硕果不学不做，安于平庸，已然是棺材里的人生","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"印象·重庆","date":"2017-05-31T11:25:07.000Z","path":"2017/05/31/印象·重庆/","text":"借着DDCLS会议之名，有幸来到山城重庆这是我第一次踏上祖国大西南的土地作为新中国最年轻的直辖市重庆有着现代化大都市的魅力作为巴蜀文化的传承者重庆又有着历史的厚重感没有工业的喧嚣，只有奔流的江水重庆还是一个恬静安逸的城市，令人留恋 1 大礼堂 了解一座城市，所以要去的当然是当地的博物馆刚下飞机，坐着机场1号线，直奔大礼堂站在汽车上，感受重庆交错的立交桥、层起彼伏的高楼不出一个小时便到达大礼堂所在地大礼堂其实是个偶遇，这是属于重庆的人民大会堂重庆作为西南重镇，从历史上就政治味道浓厚大礼堂本身没有太多看头，但恢弘的建筑还是令人振奋 2 三峡博物馆 大礼堂外面是宽广的人民广场，广场对面就是三峡博物馆三峡博物馆共四层，每层两个厅，集聚历史文物、名画佳作三峡之地是地壳运动产生的奇妙自然景观丰富的物种和矿产留下了许多珍贵的印记巴人的发展之路也充斥着文明的传播和战争的冲击三峡博物馆是个人首推，来到此处不枉重庆此行 3 解放碑 解放碑是重庆的地标式建筑周围范围广阔的商贸区彰显城市的繁华多少拔地而起的高楼恍如纽约曼哈顿（想象的）恰逢意大利时尚节，观看了一场高水平的时装表演秀周边也有不少美食街道，吸引着大量游客不过商业区除了人满为患，真正的特点并不多 4 长江索道 从解放碑往西南走不久就能到到达长江索道乘坐点我是约摸傍晚5点左右到达此处，排队游客很多排了一个多小时的队伍，上索道只待了四分钟20块钱的票价，费时的排队，还不如江边独自赏景来得惬意不过如果从南山这边上去，就几乎不用排队了迎着夕阳，打车回宾馆结束第一天的游玩重庆出租车很多，但并不好打，滴滴下单也比较慢 5 南山一棵树 第二天开会结束之后，在宾馆待到晚饭后，直奔南山一棵树去南山的路很绕，领略了山城蜿蜒的公路，不过道路设施很新南山一棵树门票30，是此次重庆之行最贵的门票到达南山才6点而已，离8点半太阳下山还有两个多小时想着到处转一转，但南山上除了一个观景台，几乎没有好去处与众多游客一样耐心等待着日落，等待着暮色的降临南山的夜景据说是重庆最美的夜景远眺长江、大桥和对岸繁华的商贸区，心情十分开阔从南山回去之路比较艰辛，很多人在等待出租车，人多车少不好等而我是一路小跑到山脚下才打车回去的，刚好体验下重庆夜跑，空气不错 6 磁器口 第三天会议结束之后，吃完中饭就坐着轻轨直奔磁器口尽管去之前，我就在网上的点评中有所心理准备但实际体验还是很糟糕，逛了大小街道，实在浪费时间磁器口号称民俗街，其实商业气息浓厚各种火锅底料、陈麻花以及毫无新意的小吃，实在无感顶着烈日实在不好受，就早早离开了此处 7 洪崖洞 从磁器口出来之后，找到一家轻轨旁的江景房略微憩息重庆的轻轨很有特色，时而穿梭地下，时而翱翔天上傍晚时分，打车来到了重庆最负盛名的景点——洪崖洞独特的溶洞地貌，浓郁的历史文化气息，洪崖洞也是必去之地洪崖洞面临嘉陵江，背靠解放碑商业区，位置极佳洪崖洞上下共11层，是我去过最热闹、繁华的民俗街琳琅满目的工艺品，遍地可见的美食，令人欣喜找了网上好评的面馆吃上一碗番茄肥牛面，十分满足最令人印象深刻的是，洪崖洞的11层居然是解放碑商业区的地面一层哎呀，重庆真就是一座建造在山上的城市啊 8 尾记此次去重庆，开会两天，前后四天，大致转了城区的著名景点感受了重庆的火红和热闹，也体验了重庆的恬美和安逸美景、美食、美人，样样惊艳，让人深深喜欢上这个城市或许，这是一个纯粹地很适合生活的城市吧返程的西部航空是我第一次坐的不提供免费餐饮的航班，同样新奇，哈哈","comments":true,"tags":[{"name":"游记","slug":"游记","permalink":"http://yoursite.com/tags/游记/"}]},{"title":"心情 2017.5.31","date":"2017-05-31T01:00:10.000Z","path":"2017/05/31/心情-2017-5-31/","text":"清晨，屋内白墙透着亮光微风拂过肌肤，格外清凉窗外鸟语花香，沁人心脾一段白纱遮掩着蓝天，略微朦胧挡不住的艳阳，迫不及待地传递它的热情 前两天刚从山城重庆出差回来利用出差开会间歇，好好走了地标性景点层起彼伏高楼和马路给人留下深刻印象美景、美食、美人，有一段特殊的体验回头找时间整理下思绪，好好写写游记 去重庆的主要目的是参加DDCLS会议之所以将会议的事情放后说是因为这个会议确实比较一般般吧桂院士的大会汇报内容在去年青岛就听过一次其他专家、学者的汇报大多与控制相关自己的论文汇报被要求以中文来进行高质量的汇报、可学到的东西乏善可陈就当作一次体验吧，多参与会更老练 端午小长假的第一天是从出差回来开始的坐着没有提供机上餐饮的西部航空回到晋江先到宿舍清洗完出差换洗的衣物之后赶回家在家里打了几盘dota，单排、开黑还有看直播两天的白天都开车回了老家多练练，确实感觉自己的车技也在成熟起来端午时节少不了粽子，南方咸粽子中的五花肉十分诱人 还有一个来自远方的消息也令人欣喜官方网站的录取名单公示了调档函和通知书不日将至接下去办手续的事情又得折腾一段时间了 另有小事一件去年买的皮带又扯断了感觉现在东西的质量真是堪忧 夏天真的来了如何过出一个清爽的夏天呢这是一门学问，得好好研究研究","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"基于状态匹配的多核RBF模型","date":"2017-05-24T07:52:26.000Z","path":"2017/05/24/基于状态匹配的多核RBF模型/","text":"本文是我参加2017年DDCLS（数据驱动控制、学习和系统）会议汇报内容整理而来，详细内容请参看发表的会议论文“An Adaptive Multi-Kernel RBF Model Using State Matching” 1 背景众所周知，系统辨识问题存在于很多领域，例如金融领域中研究股票的走势，气象领域中预测降雨可能性，交通运输领域中预测道路拥堵 然而，用过去研究的方法仍然有很多问题难以解决现实的系统几乎都是非线性和时变的，采用带有固定结构和参数的静态模型往往难以求解为了应对这样的问题，我们可以采用结构可变的模型或者直接采用组合模型，这里我们选择后者 2 RBF神经网络下图是典型的RBF神经网络结构RBF的全称是Radial Biasi Function（径向基函数），它可以完成输入层和隐层之间的高维映射正交最小二乘可以简称为OLS，采用OLS和前进法相结合，可以获得稀疏的模型结构，且能减少复杂计算量在隐层和输出层之间的参数确定采用广义逆的方法。 3 多核模型在RBF模型的基础上，针对时变系统问题，我们提出了基于状态匹配算法的多核RBF模型，简称为SMMK-RBF算法包括离线和在线过程首先，在离线过程中，我们生成数个RBF子模型，根据之前介绍的OLS模型获得稀疏解构，用历史数据来初始化子模型权重其次，在线过程中，采用状态匹配的方法来调整权重，并整合子模型的结果获得最终输出 下面详细介绍状态匹配算法的细节首先，在所有过去状态，我们都记录其最优的核；然后，针对当前状态，我们运用加权欧式距离的方法做多次匹配基于这两点，我们可以整合多个核获得最优结果这个过程就像是一般的加权投票系统，并且它是有效的 4 仿真实验接下来介绍模型的仿真实验首先是选择典型的时变时间序列：Mackey-Glass时间序列通过设置模型参数并随机生成初始长度的序列，之后采用Runge-Kutta法来生成完整序列下图展示SMMK-RBF模型的预测效果图中蓝实线和红虚线分别表示系统输出和模型预测输出，两条线相似验证了模型的有效性 为了比较我们提出的模型和其他模型，我们做了更多的数值实验所有的实际时间序列数据从UCI Machine Learning Repository获得。我们定义了均方差根作为评估模型的衡量标准其他对比选用固定参数的多核RBF模型、有300个节点的极限学习机、K近邻模型和OLS-RBF模型。从仿真结果可以看出，SMMK-RBF有最佳的效果 5 讨论为了保证模型的鲁棒性，在每时刻，我们是调整所有核的权重并带有遗忘因子，而不是直接转换到最优核然而，由于我们仅仅是关注于已存在的系统动态特性，所以未能覆盖到不可预见的特性在以后的工作中，我们将分析不同核函数在特定应用场合的适用性，并建立混合模型","comments":true,"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"心情 2017.5.21","date":"2017-05-21T08:47:13.000Z","path":"2017/05/21/心情-2017-5-21/","text":"感恩的心，感谢有你受人恩惠，没齿难忘人这一辈子，认识许许多多的人有些人擦肩而过，有些人曾提携过你永远不要忘记那些帮助过你的人 感恩家人当世界上所有人都变得冷漠但父母总会在背后默默支持你亲情有着神奇的魔力，是割不断的纽带古时候尽管有同室操戈，兄弟反目但贵族的分封制始终是以血缘为基础的这是所有生物天生的本能家永远是最温暖的港湾 感恩师长师者，所以传道授业解惑也父母把你带到了这个世界师长给了你打开未知大门的钥匙三人行必有我师焉不管是老师、学长、领导，或者是其他认识的人只要实施了传道、授业、解惑的使命，即为师者恩情虽孰轻孰重有分，但皆须勿忘之 感恩良友在家靠父母，出外靠朋友有些人交际很广，朋友遍天下有些人鲜有外访，朋友仅二三人人的经历是有限的，维系朋友的情谊也是有量的患难见良友，即心系于你，有益于你 感恩社会奉献者社会的秩序需要有一些奉献者来维护警察，保卫治安医生，救助病患官员，领导群众还有许多在各自岗位奉献的人公车司机、环卫工人、边防战士等等没有他们的付出，就没有这样美好的世界 心念感恩，让我们懂得珍惜眼前满怀感恩，让我们懂得汇报他们传递社会正能量是现在的主旋律拥有一颗感恩的心，让我们充满动力我们在别人的呵护下成长将来，我们也会呵护其他需要帮助的人 少一点抱怨，多一点感恩好的心态能让自己和别人都过得开心","comments":true,"tags":[{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"},{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"}]},{"title":"迁移学习（Transfer Learning）","date":"2017-05-17T01:18:38.000Z","path":"2017/05/17/迁移学习（Transfer-Learning）/","text":"1 迁移学习概念机器学习和数据挖掘的基本假设（1）用于学习的训练样本与新的测试样本满足独立同分布的条件（2）必须有足够多的训练样本才能学习得到一个好的分类模型然而，由于系统的特征往往会随时间改变，因此数据的特征空间和分布规律也会发生变化如果每次针对新问题都需要对数据做标签的任务，代价是十分高昂的，因此，迁移学习的目的在于应用过去的知识来快速有效解决新问题。 迁移学习可应用与分类、回归和聚类问题迁移学习与domain adaptation、multitask learning and sample selection bias、as co-variate shift等机器学习技术密切关联迁移学习最早是关注对过去知识的保留和重用（retain and reuse previously learned knowledge，NIPS-95 workshop on “Learning to Learn”）典型例子：网络文本分类、室内Wifi定位、产品效用评价迁移学习相关术语：learning to learn, life-long learning, knowledge transfer, inductive transfer, multi-task learning, knowledge consolidation, context sensitive learning, knowledge-based inductive bias, meta learning, and incremental/cumulative learning类似技术：多任务学习框架（multi-task learning framework），即基于潜在的相同特征，同时对多个不同任务进行学习 迁移学习分为[1]：：归纳式迁移学习（inductive transfer learning）， 直推式迁移学习（transductive transfer learning）和无监督迁移学习（unsupervised transfer learning）归纳式和无监督迁移学习的源任务和目标任务虽然不同但相关直推式迁移学习的源任务和目标任务则是相同的，但源域和目标域不同但相关三类问题的显著区别还体现在源域和目标域有无标签，具体如下： 迁移学习问题分类 源域标签 目标域标签 任务 相关领域 归纳式迁移学习 有/无 有 回归、分类 多任务学习/自主学习 直推式迁移学习 有 无 回归、分类 域适应性、样本选择偏差、covariate shift 无监督迁移学习 无 无 聚类、降维 - 迁移学习技巧 描述 基于实例迁移 将原问题域的标签数据重新设置权重用于目标问题 特征表达迁移 寻找合适的特征表达减少原问题和目标问题的域偏差 参数迁移 原问题和目标问题共享参数 相关知识迁移 建立原问题和目标问题的相关知识映射 迁移学习需要重点关注问题是：如何避免negative transfer，需要深入探讨定义原问题和目标问题的相似性和可迁移性为提高泛化能力，通常假设原问题的域和目标问题的域具有相同的特征空间，但具体应用场合往往是不同的，即需要采用异质迁移方法迁移学习技术应用与传感器网络定位、文本分类和图像识别，未来可拓展至视频分类、社交网络分析和逻辑推断 2 归纳式迁移学习：TrAdaBoost及其衍生算法TrAdaBoost[2]是基于实例迁移方法的一种，是AdaBoost法(Freund &amp; Schapire, 1997)的扩展。TrAdaBoost在大量原有数据的基础上利用少量的新标签数据来获得对于新数据的高质量的分类模型。用boosting的方法找出原有数据与新标签数据的异同部分，设置训练实例的权重训练标签数据分为同分布（针对于新问题）和不同分布（针对于老问题），数据的权重初始化是一样的，训练得到分类器。如果某个同分布实例预测错误，与Adaboost一样，则加大该实例权重，但如果是不同分布的实例预测错误，则认为该数据不符合新问题，减小权重具体的流程为：算法迭代5流程即为权重调整策略TrAdaBoost法收敛率基于Boosting法，为$O\\sqrt{n\\log n}$，其应用场合在于新问题的标签数据较少的情形如果新问题的标签数据足够大，可以单独训练出一个强分类器，那么TaAdaBoost方法的效果不会提升，反而可能变差AdaBoost算法随着迭代步骤增加，预测出错样本权重变得很大，可能出现过拟合 TrAdaBoost是在AdaBoost算法基础上引入的迁移学习的思想，应对源域标签数据量大，而目标域标签数据量小情况下可以取得不错的效果但是当源域数据含有较多分布的时候，效果不好下图分别是boosting和TrAdaBoost算法的分类面示意图 应对多源数据，Yao等人提出了两种TrAdaBoost的衍生算法[3]，MultiSourceTrAdaBoost和TaskTrAdaBoostMultiSourceTrAdaBoost是将同分布的源域分别和目标域训练模型，再将多个分类器结合TaskTrAdaBoost首先是只用源域数据分别训练模型，然后引入目标域数据加权综合分类器，这是基于参数迁移的方法 3 归纳式迁移学习：基于特征的迁移学习归纳式迁移学习是应用域大量源域未标签数据和少量目标域标签数据的场合Quatton等人[4]提出稀疏原型表示法基本思想是用未标签数据获取特征矩阵，用标签数据训练特征矩阵维度系数该方法类似于稀疏编码，主要应用于图像中如果有少量的属于某个topic 的图片和大量未标签的图片，可以用未标签图片构建特征空间，然后用标签数据选择合适的特征空间方法的优点是适用性强，缺点是优化问题求解困难，且容易过度适配 4 直推式迁移学习：基于特征的迁移学习直推式迁移学习是应用于源域标签数据和目标域未标签数据的场合用标签数据来标定未标签数据，但不能直接用，需要进行转换，例如文本分类Pan等人提出了维度约减的方法[5]，基本思想是：（1）将标签和未标签数据的输入映射到低维空间，再用合适核映射使得俩数据集尽可能相似（2）用上述映射得到的标签数据输入和对应输出训练得到分类器，然后对未标签数据进行分类（3）对新的未标签数据，应用harmonic function（未标签数据由近邻标签数据加权平均） Long等人提出深度适应网络的方法[6]将CNN（AlexNet）中与学习任务相关的隐藏层映射到再生核希尔伯特空间中通过多核优化的方法（MK-MMD）最小化不同域之间的距离 5 无监督迁移学习：自学习聚类无监督迁移学习是应用域少量未标签数据的情况如果数据量大可以使用传统方法，但数据量小传统方法效果不好Dai等人提出自学习聚类法[7]，基本思想是构建共同特征空间Z，同时目标数据X和辅助数据Y（大量）聚类目标函数根据互信息理论定义的，而可将其转化为KL散度的表达式 6 总结迁移学习的适用性：（1）问题之间需要有共同要素，具有相似的分布规律、可提取共同的特征等（2）知识的概括度要高，对问题进行抽象，概括本质属性，舍弃偶然属性 迁移学习的未来研究方向：（1）域相似性及共同特征，现有VC维、散度等理论还不成熟——研究合适度量方法（2）目前还是以分类回归居多——研究更广泛的应用领域（3）目前相关理论较多，缺乏统一理论——研究统一的迁移学习理论 最后是一张2016年Andrew Ng在NIPS会上报告关于机器学习发展趋势的论断监督学习一直是机器学习的主导，过去，现在，未来一直是但是迁移学习、强化学习等新兴学习问题会在未来机器学习领域作用也会越来越大 参考文献1.Pan S J, Yang Q. A Survey on Transfer Learning. IEEE Transactions on Knowledge &amp; Data Engineering, 2010, 22(10):1345-1359. ↩2.W Dai, Q Yang, GR Xue, Y Yu. Boosting for transfer learning. International Conference on Machine Learning, 2007, 238 (6) :193-2000. ↩3.Yao Y, Doretto G. Boosting for transfer learning with multiple sources. IEEE Conference on CVPR, 2010:1855-1862. ↩4.Quattoni A, Collins M, Darrell T. Transfer Learning for Image Classification with Sparse Prototype Representations. 2008:1-8. ↩5.Pan S J, Kwok J T, Yang Q. Transfer learning via dimensionality reduction. AAAI Conference on Artificial Intelligence, 2008:677-682. ↩6.Long M, Cao Y, Wang J, et al. Learning Transferable Features with Deep Adaptation Networks. Computer Science, 2015:97-105. ↩7.Dai W, Yang Q, Xue G R, et al. Self-taught clustering. International Conference. DBLP, 2008:200-207. ↩","comments":true,"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"心情 2017.5.15","date":"2017-05-15T01:57:16.000Z","path":"2017/05/15/心情-2017-5-15/","text":"生活不仅有波澜壮阔的汪洋也有细雨闲情的自在随着阅历的不断增加人的心静也逐渐变得成熟稳重宠辱不惊，处事井然，大概就这样 周一的上班是从赶班车开始的从家里出发就想着一路上的行程一回生，二回熟刚开始不熟，几次之后就是习惯了人有些时候的担心就在于没有去尝试过 没坐过火车的人，可能对站台没有概念没坐过飞机的人，可能不懂得值机要提前当你一样样去经历之后其实一切都很简单担心是因为没有经历过 中学时代没怎么去过其他地方担心以后上大学普通话交流会有问题这种担心就完全是不必要的有点口音，但人家也听得懂，而且慢慢淡化了学了十几年的英语，长期在国内呆着一直觉得自己英语水平差其实没准到了国外，有了语言环境，就是so easy担心是因为对未知的恐惧和对自己的没有信心 有些事情，不敢尝试去做的话永远不知道自己会做得怎样“犹豫的时候，就憧憬五年后自己的样子”（by有个同事）决定很关键，决定也不关键犹豫不决，是因为担心和害怕做决定如果能够坦然按照自己所期望的样子去执行也就无所谓决定不决定了，事情总会往好的发展当自己不确定好与不好的时候，这种情况往往不多 每个人心中有把平衡秤小时候天平支撑重心不稳，能够做出正确判断较少后来阅历增加了，支撑柱粗了，底座稳了，也就靠谱了看书学习，是增加天平筹码的精细度，能衡量更精确好的天平，“能让自己在对的时间做该做的事情”（by有个同学） “羽扇纶巾，谈笑间樯橹灰飞烟灭”饱读诗书，遍览兵法，周郎何等英姿这个世界，缤纷缭绕，舞台很多但上舞台需要十年功，需要千锤百炼有志者事竟成，破釜沉舟，百万雄关终属楚有心人天不负，卧薪藏胆，三千越甲可吞吴 个人心情随便往往没有太多逻辑，字随心想成功前大多孤独，但孤独时需要不断地自我暗示","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.5.7","date":"2017-05-07T02:18:35.000Z","path":"2017/05/07/心情-2017-5-7/","text":"今天心情的主题是数学之美最近补充大学数学课程，引发感触谈起数学，很多人会为之色变而我对于数学却有更多的情愫既爱又恨，仍是那么难以割舍以下就回忆我对于数学的点点滴滴 数学在很多人的眼中也许是一门很难的学科但我可能理解强些，也包括那份挚爱，成绩一直不错三年级转学第一次考试的120分（20附加分）六年级期中考及之前三四次考试全部满分这些“光辉”的记忆一直留在脑海里由于小时候资源有限，书本课后的动脑筋题目成为了个人乐趣 初中的时候也偶尔拿到满分然而在竞赛方面比较惨淡几番希望杯的折戟十分落寞但也因数学，结缘了ta 高中时候，庆幸14班与GH同班尽管成绩一直不如他，但也算紧追不舍分班之后，基本上保持10班第一，鲜有失手不得不提的是奥赛班的经历过程算是边玩边学过来的，还算有趣然而最终考试167以一分之差失去高考加分机会十分惋惜可幸的是，从此之后，直到高考所有考试从未低于140 进入大学之后，开始进入学习的迷茫期大学的纷乱让自己不能自已虽有高数上的100分，但仍难以遮掩成绩的不如意同学他们在积极参加数学竞赛，而我连课内知识都不是很扎实直到本科毕设之后，我的大学数学学习才算进入正轨 像大部分学科一样，数学也有很多的分支统计学、矩阵学、积分学、复变函数等等数学是所有学科的基础，也是给我们搞科研的基础这是现在我身边的同学、同事公认的事实尤其是在论文撰写，好的论文大多离不开数学的严密推导 很多人觉得的数学可能就是眼花缭乱的公式其实究其本源，最难的是蕴含的数学定义和逻辑真正理解一个数学理论，从理论推导到实际应用都需要掌握拿傅立叶变换为例，高数学的，当时只会计算就不错了直到最近接触时域-频率转化、时序数据降维等才了解其应用数学常常还是由浅入深，这也跟学习的不同阶段有关系比如积分，从黎曼积分、斯蒂尔杰斯积分、勒贝格积分，形成系统化 数学的魅力就在于用许多认为定义的理论来解释科学计算问题从古至今，多少数学家前赴后继，提出各种美丽的理论欧几里德、欧拉、笛卡尔、高斯、傅立叶、费马，以及国内的华罗庚、陈景润他们用努力创造着这门学科，给后来人打开未知世界的钥匙这些所有的所有，无一是我的偶像 而今天，我在通过不断的学习充实自己的数学知识体系尝试用数学的观点去解释所在领域的科学问题数学是一把历经千年的宝剑真正能用其发挥效用，需要不断磨砺出锐利的锋芒而且还要针对问题，切入要害，这则需要长时间的经验科研之路漫漫，而我与数学之间擦出的火花才刚刚要绽放出光彩","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.5.1","date":"2017-05-01T01:38:24.000Z","path":"2017/05/01/心情-2017-5-1/","text":"早上睡到自然醒来今天是五一节了夏天的脚步终于还是来到了外面风和日丽，而我在屋里独处阴凉一个人的节日向来并不孤单因为我有一百种自娱自乐的方式 最近的工作百无聊赖刷着教程，码着code，写着博客突然想起要提高下“数学涵养”数学分析、数值分析、矩阵理论，通通袭来空闲之余就是好好整理好心情，等待出发 生活的节奏是一支独奏曲街边的人来人往，都影响不到耳机里的旋律一个人走在马路上时而驻足观光，时而仰天想事儿就是心情有点容易受天气干扰，不喜欢下雨天 人类之所以能成为食物链的顶端努力奋斗和残暴贪婪同样重要物欲社会，好比数百万年前的野生世界钱权当上，这个舞台的聚光灯只会展现胜者的姿态没人关心，成功者脚下踩着的多少loser的尸体自古以来，君王都是孤家寡人拥抱孤独，一个人的生活要尽量精彩 马克思憧憬的“共产社会”前路漫漫物质极大丰富，需要拓荒者人人友好社会，需要秩序领导者社会的高效运行离不开分工协作分工协作就没有完全等分的蛋糕至少，拿刀切蛋糕的人也是掌权者 也许思维有点局限也行心态太过黑暗其实以自我为中心与为人民服务并不矛盾创造个人价值的体现在于给其他人创造多少价值总和市长政绩与全市GDP是分不开的至于能不能做到全心全意公道自在人心，这个并没有标准 扯远了，我只是一只雏鸟，羽翼还未丰满需要锤炼，需要等待机会","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"概率密度估计之Parzen Window","date":"2017-04-27T11:57:56.000Z","path":"2017/04/27/Parzen-Window/","text":"kernel density estimation是在概率论中用来估计未知的密度函数，属于非参数检验方法之一，由Rosenblatt (1955)和Emanuel Parzen(1962)提出，又名Parzen窗（Parzen window）本文翻译自英国雷丁大学（Reading University）Xia Hong老师的讲义材料 概率密度函数连续概率函数$p(x)$的数学定义满足以下特性： $x$介于$a$、$b$两点之间的概率为$P(a&lt;x&lt;b)=\\int_a^bp(x)dx$ x是非负实数 概率函数的积分：$\\int_{-\\infty}^\\infty p(x)dx=1$ 最常见的概率函数是高斯函数（Gaussian Function，又称为正态分布）：$p(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(-\\frac{(x-c)^2}{2\\sigma^2})$，这里$c$是均值，$\\sigma$是标准差 拓展到对于向量$\\mathbf{x}$，非负函数$p(\\mathbf{x})$有以下特性： $\\mathbf{x}$在区域$R$里的概率为$P=\\int_R p(\\mathbf{x})d\\mathbf{x}$ 概率函数的积分为$\\int p(\\mathbf{x})d\\mathbf{x}=1$ 密度估计密度估计：给定的一系列数量为$n$的样本$\\mathbf{x}_1, \\cdot\\cdot\\cdot,\\mathbf{x}_n$，可以估计密度函数$p(\\mathbf{x})$，从而根据任意新样本$\\mathbf{x}$可以得到输出$p(\\mathbf{x})$大部分未知密度函数估计方法的基本思想都很简单，主要是依赖于样本落在区域$R$的概率$P$，即有$P=\\int_R p(\\mathbf{x})d\\mathbf{x}$假设区域$R$很小，$P(\\mathbf{x})$在区域内波动很小，上式可以写做$P=\\int_R p(\\mathbf{x})d\\mathbf{x}\\approx p(\\mathbf{x})\\int_R d\\mathbf{x}=p(\\mathbf{x})V$，这里$V$是区域$R$的“量”（二维即为面积）从另一方面看，假设$n$个样本$\\mathbf{x}_1, \\cdot\\cdot\\cdot,\\mathbf{x}_n$都是独立且服从概率密度函数$p(\\mathbf{x})$，且$n$个样本中有$k$个落在区域$R$里面，则有$P=k/n$，因此$p(\\mathbf{x})$的估计式为$p(\\mathbf{x})=\\frac{k/n}{V}$ Parzen窗密度估计考虑$R$是中心在$\\mathbf{x}$的超立方体（例如二维平面），令$h$为超立方体的边缘长度，所以对于二维平面有有$V=h^2$，对于三维立体有$V=h^3$ 引入$\\phi(\\frac{\\mathbf{x}_i-\\mathbf{x}}{h})=\\left\\{\\begin{aligned}1\\quad&amp; \\frac{|x_{ik}-x_{k}|}{h}&lt;=1/2, k=1,2 \\\\0\\quad&amp; otherwise\\end{aligned}\\right.$Parzen概率密度公式（二维）为$p(\\mathbf{x})=\\frac{k/n}{V}=\\frac{1}{n}\\sum_{i=1}^n {\\frac{1}{h^2}\\phi(\\frac{\\mathbf{x}_i-\\mathbf{x}}{h})}$，$\\phi(\\frac{\\mathbf{x}_i-\\mathbf{x}}{h})$即为窗函数我们归纳这个思想并拓展到其他Parzen窗密度估计法中例如，如果使用高斯函数，对于一维有：$p(x)=\\frac{1}{n}\\sum_{i=1}^{n}{\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(-\\frac{(x_i-x)^2}{2\\sigma^2})}$，这是对$n$个将数据点作为中心的高斯函数的简单求平均，公式中的$\\sigma$需要再做确定 例子：给定一个系列的5个数据点$x_1=2$，$x_2=2.5$，$x_3=3$，$x_4=1$，$x_5=6$，参数$\\sigma=1$，中心$x=3$的高斯函数作为窗函数，求出Parzen概率密度估计（pdf）解答：$\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(x_1-x)^2}{2})=\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(2-3)^2}{2})=0.2420$$\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(x_2-x)^2}{2})=\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(2.5-3)^2}{2})=0.3521$$\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(x_3-x)^2}{2})=\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(3-3)^2}{2})=0.3989$$\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(x_4-x)^2}{2})=\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(1-3)^2}{2})=0.0540$$\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(x_5-x)^2}{2})=\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(6-3)^2}{2})=0.0044$因此，$p(x=3)=(0.2420 + 0.3521 + 0.3989+0.0540 + 0.0044)/5 = 0.2103$ 下面用图形化语言表示Parzen窗，每个数据点密度函数（虚线）对于最终的概率密度函数（实线）有相同的贡献度","comments":true,"tags":[{"name":"统计分析","slug":"统计分析","permalink":"http://yoursite.com/tags/统计分析/"}]},{"title":"心情 2017.4.23","date":"2017-04-23T04:05:39.000Z","path":"2017/04/23/心情-2017-4-23/","text":"今天心情的主题是遨游（Roaming）鱼儿驰骋于浩瀚的大海，鸟儿奔腾于苍茫的蓝天，这就是遨游——大鹏一日乘风起，扶摇直上九千里！闲时捧起一本书，思绪在文字间游荡，感受作者的情怀，也是一种遨游——胸藏文墨怀若谷，腹有诗书气自华！常说要活到老，学到老，世间知识无限，知识海洋里遨游更具吸引力 最近组里的匆忙节奏骤停，多了不少闲暇时间有了时间，自然要想着合理安排，不能荒废看看论文，交通期刊、机器学习会议论文太多，大多泛看，偶尔精读，多做笔记看看教材，算法基础、可视化教程、机器学习总结，甚至是数学书，巩固自己的知识体系看看编程，主攻Python，兼顾web可视化（html+CSS+PHP），以及数据库方面的，锤炼技术最近看得多了，时常提醒自己注意总结，养成写技术博客的习惯，方便自己以后时常回顾 Kindle的价值1000元，以寿命2年，相当于30~40本书，也就是每个月1本书——中规中矩多级时间，多看益书，多长见识——价值放大十倍学于书，长其智，修其身——受益终生读书不是读给别人看，而是读给自己的，带着思辨态度，多看多思考看剧不如看书，打游戏不如看书，流连于社交网站不如看书，谨记之！ 英语是个人成长的另一必要本领不管专业知识好坏，英语好准没错，现扇贝打卡400多天了从单词、口语、听力一路走来，现在需要重点强化阅读和理解坚持每天打卡，用老李话说，砸入时间自然会有成果期待一口流利英语和论文“write well”的那一天 强身健体，这是需要用一辈子践行的事情跑步、练肌肉，给自己一副健壮的体格，提高病毒免疫力早睡早起，规矩饮食，保持良好的身体状态爱护身体，注重保养，保持年轻范、自信范，王大boss是好榜样（自信=昂首挺胸、话语洪亮、姿态得体、保持微笑）","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"python网络爬虫","date":"2017-04-21T02:41:06.000Z","path":"2017/04/21/python网络爬虫/","text":"——问：“如何完成《大卫》这样杰出的作品”——米开朗基罗答：“很简单，只要用锤子把石头上不像大卫的地方敲掉就可以了！” 采集信息用的程序一般被称为网络爬虫（ Web crawler）、网络铲（ Web scraper，可类比考古用的洛阳铲）、网络蜘蛛（ Web spider），其行为一般是先“爬”到对应的网页上，再把需要的信息“铲”下来。网络数据采集是普通大众细纹乐见的计算机巫术，在信息爆炸的时代，互联网上充斥着大量信息，网络爬虫是获取网络上的信息资源的有效手段。Python在爬虫编程上有 urllib、BeautifulSoup、 lxml、Scrapy、 PdfMiner、 Requests、 Selenium、 NLTK、 Pillow、 unittest、 PySocks 等模块，对于爱好Python的编程者来说，爬虫必然得学。 1 用urlopen获取url，用BeautifulSoup读取网页信息12345678910111213141516171819from urllib.request import urlopenfrom urllib.error import HTTPErrorfrom bs4 import BeautifulSoupdef getTitle(url): try: html = urlopen(url) except HTTPError as e: return None try: bsObj = BeautifulSoup(html.read(), \"lxml\")#读取网页，不加\"lxml\"会有警告 title = bsObj.body.h1#根据需要选择网页标签内的内容 except AttributeError as e: return None return titletitle = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")if title == None: print(\"Title could not be found\")else: print(title) 2 用find/findAll选取特定网页的内容1234567from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen(\"http://www.pythonscraping.com/pages/warandpeace.html\")bsObj = BeautifulSoup(html,'lxml')nameList = bsObj.findAll(\"span\", &#123;\"class\":\"green\"&#125;)for name in nameList: print(name.get_text()) find(tag, arributes, recursive, text, limit, key words)findall(tag, arributes, recursive, text, keywords)find()只读取一个，findall()读取所有内容 3 Regex正则表达式*：重复任意次，(|)：或，+：出现多次，且至少1次，\\：转义12345678from urllib.request import urlopenfrom bs4 import BeautifulSoupimport rehtml = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")bsObj = BeautifulSoup(html,'lxml')images = bsObj.findAll(\"img\",&#123;\"src\":re.compile(\"\\.\\.\\/img\\/gifts/img.*\\.jpg\")&#125;)for image in images: print(image[\"src\"]) 4 用urlretrieve下载网络资源1234567891011121314151617181920212223242526272829303132333435import osfrom urllib.request import urlretrievefrom urllib.request import urlopenfrom bs4 import BeautifulSoupdownloadDirectory = \"downloaded\"baseUrl = \"http://pythonscraping.com\"def getAbsoluteURL(baseUrl, source): if source.startswith(\"http://www.\"): url = \"http://\"+source[11:] elif source.startswith(\"http://\"): url = source elif source.startswith(\"www.\"): url = source[4:] url = \"http://\"+source else: url = baseUrl+\"/\"+source if baseUrl not in url: return None return urldef getDownloadPath(baseUrl, absoluteUrl, downloadDirectory): path = absoluteUrl.replace(\"www.\", \"\") path = path.replace(baseUrl, \"\") path = downloadDirectory+path directory = os.path.dirname(path) if not os.path.exists(directory): os.makedirs(directory) return pathhtml = urlopen(\"http://www.pythonscraping.com\")bsObj = BeautifulSoup(html,'lxml')downloadList = bsObj.findAll(src=True)for download in downloadList: fileUrl = getAbsoluteURL(baseUrl, download[\"src\"]) if fileUrl is not None: print(fileUrl)urlretrieve(fileUrl, getDownloadPath(baseUrl, fileUrl, downloadDirectory)) 5 保存成csv文件123456789101112131415161718import csvfrom urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen(\"http://en.wikipedia.org/wiki/Comparison_of_text_editors\")bsObj = BeautifulSoup(html,'lxml')# 主对比表格是当前页面上的第一个表格table = bsObj.findAll(\"table\",&#123;\"class\":\"wikitable\"&#125;)[0]rows = table.findAll(\"tr\")csvFile = open(\"./files/editors.csv\", 'wt', newline=\"\", encoding='utf-8')writer = csv.writer(csvFile)try: for row in rows: csvRow = [] for cell in row.findAll(['td', 'th']): csvRow.append(cell.get_text()) writer.writerow(csvRow)finally: csvFile.close() 6 读取网络中的word文件123456789101112from zipfile import ZipFilefrom urllib.request import urlopenfrom io import BytesIOfrom bs4 import BeautifulSoupwordFile = urlopen(\"http://pythonscraping.com/pages/AWordDocument.docx\").read()wordFile = BytesIO(wordFile)document = ZipFile(wordFile)xml_content = document.read('word/document.xml')wordObj = BeautifulSoup(xml_content.decode('utf-8'))textStrings = wordObj.findAll(\"w:t\")for textElem in textStrings: print(textElem.text) 7 实战(1)：爬取豆瓣专栏书目，并保存为csv文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#coding=utf-8from urllib.request import urlopenfrom urllib.error import HTTPErrorfrom bs4 import BeautifulSoupimport timeimport pdbimport csvnum = 0 #用来计数，计算爬取的书一共有多少本start_time = time.time() #计算爬虫爬取过程时间#第一页网页网址https://read.douban.com/columns/category/all?sort=hot&amp;start=0#第二页网页网址https://read.douban.com/columns/category/all?sort=hot&amp;start=10#第三页网页网址https://read.douban.com/columns/category/all?sort=hot&amp;start=20#以此类推，0，10，20，30，40，……url = 'https://read.douban.com/columns/category/all?sort=hot&amp;start=' csvFile = open(\"./bookCollect.csv\", 'wt', newline=\"\", encoding='utf-8')writer = csv.writer(csvFile)writer.writerow(['序号','书名','作者','类型'])i = 0#for i in range(0,1000,10): #这里的 range（初始，结束，间隔）judgement = 'n'while(judgement == 'n'): #urllib.request库用来向该网服务器发送请求，请求打开该网址链接 try: html = urlopen('https://read.douban.com/columns/category/all?sort=hot&amp;start=%d' % i) #BeautifulSoup库解析获得的网页，第二个参数一定记住要写上‘lxml’，记住就行 bsObj = BeautifulSoup(html,'lxml') print('==============' + '第%d页'%(i/10 + 1) + '==============') print('序号',' ','书名/作者/类型') contentList = bsObj.findAll('h4')#获取h4标签内的a标签，但这里返回是只含1个元素的list contentList = bsObj.find(\"div\",&#123;'class':'bd'&#125;).contents[0] for item in contentList: num = num + 1 #pdb.set_trace() bookName = item.h4.contents[0].contents[0] #contents将子节点列表输出 author = item.find(\"div\",&#123;\"class\",\"author\"&#125;).contents[1].contents[0] bookCategory = item.find(\"div\",&#123;\"class\",\"category\"&#125;).contents[1].replace('\\n','') try: print('%04d'%num, bookName, '/', author, '/', bookCategory) writer.writerow(['%04d'%num, bookName, author, bookCategory]) except Exception as e: print('%04d'%num, \"book's name not be found\") writer.writerow(['%04d'%num, \"book's name not be found\"]) except HTTPError as e: writer.writerow(['The page can not be opened']) #设置抓数据停顿时间为1秒，防止过于频繁访问该网站，被封 print(\"--\") print(\"Whether to continue? ['n': next page, 's': stoping the program]\") keyInput = input(\"Please enter your input (default: 'n'):\") if keyInput == '' or keyInput == 'n': judgement = 'n' else: judgement = 's' i = i + 10 time.sleep(0.5) csvFile.close()end_time = time.time()duration_time = end_time - start_timeprint('运行时间共：%.2f' % duration_time + '秒')print('共抓到%d本书名'%num, '详细内容见 bookCollect.csv') 运行结果：命令框：bookCollect.csv文件： 8 实战(2)：爬取淘女郎图片123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114import osimport threadingimport refrom bs4 import BeautifulSoupfrom urllib.request import urlopenfrom selenium import webdriverimport socketfrom multiprocessing import Pool # 由于urllib在获取网络信息经常出现timeout错误，下两行是网友推荐方法，但效果貌似不明显import requests.packages.urllib3.util.ssl_requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS = 'ALL'# phantomjs浏览器的位置，需要提前安装好，并将路径添加到环境变量browserPath = 'D:\\\\desktop\\\\python\\\\phantomjs-2.1.1-windows\\\\bin\\\\phantomjs'# 爬虫主页面homePage = 'https://mm.taobao.com/search_tstar_model.htm?'outputDir = 'photo/'# 网页解析器，之前是'html5lib'会出错，改成'lxml'就没事了parser = 'lxml'def main(): driver = webdriver.PhantomJS(executable_path=browserPath) #浏览器的地址 driver.get(homePage) #访问目标网页地址 bsObj = BeautifulSoup(driver.page_source, parser) #解析目标网页的 Html 源码 print(\"[*]OK GET Page\") girlsList = driver.find_element_by_id('J_GirlsList').text.split( '\\n') #获得主页上所有妹子的姓名、所在城市、身高、体重等信息 imagesUrl = re.findall('\\/\\/gtd\\.alicdn\\.com\\/sns_logo.*\\.jpg', driver.page_source) #获取所有妹子的封面图片 girlsUrl = bsObj.find_all( \"a\", &#123;\"href\": re.compile(\"\\/\\/.*\\.htm\\?(userId=)\\d*\")&#125;) #解析出妹子的个人主页地址等信息 # 所有妹子的名字地点 girlsNL = girlsList[::3] # 所有妹子的身高体重 girlsHW = girlsList[1::3] # 所有妹子的个人主页地址 girlsHURL = [('http:' + i['href']) for i in girlsUrl] # 所有妹子的封面图片地址 girlsPhotoURL = [('https:' + i) for i in imagesUrl] # zip函数接受0个或多个序列作为参数，返回一个tuple列表，第n次从各个序列分别取第n个作为tuple girlsInfo = zip(girlsNL, girlsHW, girlsHURL, girlsPhotoURL) gitlsDeff = [] for item in girlsInfo: gitlsDeff.append(item) # pool函数来实现多线程，线程数看计算机性能，多线程效率大大提升 pool = Pool() pool.map(downloadimages, gitlsDeff) pool.close() pool.join() driver.close()def downloadimages(item): girlNL = item[0] # 姓名地址 girlHW = item[1] # 身高体重 girlHURL = item[2] # 个人主页地址 girlCover = item[3] # 封面图片 print(\"[*]Girl :\", girlNL, girlHW) # 为妹子建立文件夹 mkdir(outputDir + girlNL) print(\" [*]saving...\") # 获取妹子封面图片 data = urlopen(girlCover).read() with open(outputDir + girlNL + '/0_cover.jpg', 'wb') as f: f.write(data) print(\" [+]Loading Cover... \") # 获取妹子个人主页中的图片 getImgs(girlHURL, outputDir + girlNL)def mkdir(path): # 判断路径是否存在 isExists = os.path.exists(path) # 判断结果 if not isExists: # 如果不存在则创建目录 print(\" [*]新建了文件夹\", path) # 创建目录操作函数 os.makedirs(path) else: # 如果目录存在则不创建，并提示目录已存在 print(' [+]文件夹', path, '已创建')def getImgs(url, path): driver = webdriver.PhantomJS(executable_path=browserPath) # 设置读取时间，防止程序卡住 socket.setdefaulttimeout(15) try: driver.get(url) except socket.timeout: pass #send ESCAPE key to browser print(\" [*]Opening...\") bsObj = BeautifulSoup(driver.page_source, parser) #获得模特个人页面上的艺术照地址 imgs = bsObj.find_all(\"img\", &#123;\"src\": re.compile(\".*\\.jpg\")&#125;) for i, img in enumerate(imgs[1:]): #不包含与封面图片一样的头像 try: html = urlopen('https:' + img['src']) data = html.read() fileName = \"&#123;&#125;/&#123;&#125;.jpg\".format(path, i + 1) print(\" [+]Loading...\", fileName) socket.setdefaulttimeout(15) try: with open(fileName, 'wb') as f: f.write(data) except socket.timeout: pass except Exception: print(\" [!]Address Error!\") driver.close()if __name__ == '__main__': if not os.path.exists(outputDir): os.makedirs(outputDir) main() 运行结果：本地photo文件夹：","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"Web编程基础知识","date":"2017-04-20T08:43:06.000Z","path":"2017/04/20/Web编程基础知识/","text":"前段时间零零碎碎看了Web编程相关内容，今天就整理了一下Web编程，前端主要是html+CSS+JavaScript，后端使用最多的是PHP+MySQL此次教程主要是关于html、CSS、JavaScript和PHP的一些语法和使用细则 1 Html: HyperText Markup Language，超文本标记语言，网络内容载体(1) Html是网页内容载体、CSS（层叠样式表）样式是表现、JavaScript是用来实现网页的特效效果(2) Html语言不分大小写，但建议使用小写(3) 常用标签：12345678910111213141516&lt;html&gt;根标签&lt;/html&gt;；&lt;head&gt;头部标签&lt;/head&gt;；&lt;h1&gt;标题&lt;/h1&gt;，h1-h6；&lt;p&gt;段落标签&lt;/p&gt;；&lt;img src=’1.jpg’&gt;插入图片；&lt;span&gt;特殊样式&lt;/span&gt;；&lt;q&gt;引用&lt;/q&gt;，&lt;blockquote&gt;长文本引用&lt;/blockquote&gt;&lt;br /&gt;或者&lt;br&gt;回车，&amp;nbsp;空格，&lt;hr /&gt;或者&lt;hr&gt;横线；&lt;address&gt;&lt;/address&gt;地址；&lt;code&gt;&lt;/code&gt;代码，&lt;pre&gt;多行代码；&lt;ul&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;…&lt;/ul&gt;无序列表，&lt;ol&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;…&lt;/ol&gt;有序列表；&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;td&gt;表格；&lt;a herf =’’title=’’target=’’&gt;链接；&lt;text area cols=’’rows=’’&gt;文本域&lt;select&gt;下拉`&lt;!--注释文字--&gt;` (4) html样式123456789&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt;&lt;/head&gt;&lt;body&gt;&#123;content&#125;&lt;/body&gt;&lt;/html&gt; 2 CSS: Cascading Style Sheets，层叠样式表，网页样式表现(1) CSS样式包含内联式、嵌入式、外部式，优先次序依次(2) 选择器包含：选择器、类选择器、id选择器、后代选择器、子选择器、伪选择器、分担选择符(3) 权值大小决定样式，标签1，类10，id100，!important 最高权值(4) 字体属性：font-size、font-family、font-weight(bold/italic)…(5) 元素包含块、内联、内联-块，display（inline、block、inline-block）(6) CSS布局：流动模型、浮动模型、层模型 3 JavaScript，脚本语言，用来实现网页的动态效果(1) 调用样式：12&lt;script type = \"text/javascript\"&gt;&lt;/script&gt;&lt;script src=\"script.js\"&gt;&lt;/script&gt; (2) JavaScript作为脚本语言可以放在html任何位置，浏览器按先后顺序进行解释，一般置于head和body之间(3) 单行注释//……和多行注释/*……*/(4) var a：定义变量名（字母/_/$开头）(5) JS区分大小写(6) if(){} else{}(7) 确认对话框：var message = confirm(&quot;……&quot;)(8) 提问对话框：var myname = prompt(&quot;……&quot;)(9) 打开新窗口：window.open([url],[name],[param])， [name]: _blank(新窗口) /_self(当前窗口)/_top(框架网页上部) [param]: top|left|right|width|height: 50px/menubar|toolbar|scrollbars|status: yes|no(10) 关闭窗口：window.close()(11) alert(): 警告(12) document.writ()：输出文本(13) document.getElementByid(&#39;&#39;)：通过ID获取元素(14) NaN(Not a Number)，与任何数都不相等，判断用isNaN(NaN), Infinity(无穷大)(15) 或/且/非: &amp;&amp; / || / !(16) 等号用===(不会转换数据类型)，不用==(17) 浮点比较用差值：Math.abs(1/3 -(1-2/3))&lt;0.000001(18) 空值：JavaScript(null)/swift(nil)/Java(null)/Python(None)(19) 数组：var arr = [1,2,3,null,true]/new Array(1,2,3,null,true)(20) 对象：var person = {name:&#39;bob&#39;,age:20,···}(21) JavaScript是动态语言，var a=123;a=&#39;ABC&#39;;不会报错, Java里就会报错(22) 变量未声明即为全局变量，&#39;use strict&#39;变量强制需要声明才能使用(23) \\用于转义，反引号hello表示多行字符串(24) 操作字符串：var s=&#39;hello&#39;, s.length, s[0](超出不会报错，返回undefined), toIpperCase, toLowerCase, substring(0,2)(25) 操作数组：arr.length,arr.slice(),arr.push(),arr.pop(),arr.unshift(),arr.shift(),arr.soft(),arr.reverse(),arr.splice(),concat(): 连接数组，arr.join(&#39;-&#39;): 替换逗号，变为字符串(26) for (var key in …), while, do...while, for...of(27) RegEXP: \\d: 匹配一个数字,\\w: 匹配一个字母或数字,.: 匹配任何字符,*: 匹配至少一个字符,?: 匹配0个或1个任意字符,{n}：n个字符(28) JSON: JavaScript Object Notation, JS 对象标记, 轻量级的数据交换格式，var json = &#39;{&quot;a&quot;: &quot;Hello&quot;, &quot;b&quot;: &quot;World&quot;}&#39;(对比xml)(29) 面向对象：var Student{}, var xiaoming = {}, xiaoming._proto_ = student 4 PHP（外文名：PHP: Hypertext Preprocessor，中文名：“超文本预处理器”）(1) 创建动态交互性站点强有力的服务器端脚本语言（后端语言）(2) 引用格式：123&lt;?phpecho \"我的第一段PHP脚本\"?&gt; (3) WordPress、Facebook、Twitter核心都是PHP(4) 功能包括：生成动态页面、创建/打开/读取/写入/删除/关闭服务器文件、接受表单、发送并取回cookie。数据库、限制访问、数据加密(5) PHP可运行于各种平台，多种服务器（Apache、IIS）、多数据源、免费、易于学习(6) 注释用//、#、/*...*/(7) 函数、类、关键词对大小写不敏感，变量对大小写敏感（以$开头，常量不加$）(8) 变量无需定义类型，三种作用域（local、global、static）(9) echo(无返回值)和print(返回值1)，用于输出(10) str()字符串长度(11) strpos(&#39;hello world&#39;, &#39;world&#39;)，匹配返回（true和flase）(12) 等号用===(不会转换数据类型)，不用==(13) document.getElementByid(‘’)：通过ID获取元素(14) NaN(Not a Number)，与任何数都不相等，判断用isNaN(NaN), Infinity(无穷大)(15) 与：&amp;&amp;/and，或：or/||，非：！，异或：Xor","comments":true,"tags":[{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"},{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"},{"name":"CSS","slug":"CSS","permalink":"http://yoursite.com/tags/CSS/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"},{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"}]},{"title":"心情 2017.4.15","date":"2017-04-15T12:58:34.000Z","path":"2017/04/15/心情-2017-4-15/","text":"周六晚上九点，办公室电脑，Sublime一个人静静待着，写博客，看直播，哼着歌窗外的蝉声应和着夏天的轻风屋里的键盘声此起彼伏幻想着的勤劳的周末，其实是惬意的周末这周没回家是因为明天早上所里组织去野炊+真人CS相对来说，我还是更倾向于回家，回家的那种安逸感令人难以拒绝然而，我还是决定去参加活动，可能不去的理由听起来还不够充分吧不是我排斥集体活动，跟聚餐的观点一致，关键在于人一群人一分为二，终于热情大于了冷漠，也许这才是去的理由吧 最近的工作略为烦闷，原因是无所事事时间不多，不能继续做点科研，写写文章项目的事情进展很慢，查找资料的事情十分无聊服务器调试困难，太浪费时间，不太情愿做可视化学习之路感觉眼花缭乱，没有具体项目有点迷茫接下去可能还是多抽出时间，多看点高水平的文献，积攒知识 一个人的生活进展了一年，逐渐觉得有点孤单了但是，要想有所作为，就要耐得住寂寞，自己尚需加油独处的日子要懂的自娱自乐，看书看剧健身听音乐坚持早睡，少玩游戏，爱卫生，坚持学英语生活是过给自己看的，把属于自己的日子过得精彩","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"Processing入门教程","date":"2017-04-15T08:34:50.000Z","path":"2017/04/15/Processing入门教程/","text":"0 几句话概述Processing是为开发面向图形的应用而生的简单易用的编程语言和编程环境特点是算法动画和即时交互，应用于复杂数据可视化、视觉设计和原型开发Processing是基于Java开发的，但代码不同于Java，使用时需要先配置Java环境Processing 的工程界面是Sketch（代码素描本），文件格式.Pde，支持多运行模式:Java模式输出桌面应用，Android模式输出安卓程序，JavaScript输出嵌入Web的AppletSetup()设定窗口大小；draw()绘制图像；右键函数有官方文档；“//”用来注释代码 1 认识ProcessingProcessing 在 2001 年诞生于麻省理工学院（MIT）的媒体实验室，主创者为 Ben Fry 和 Casey Reas，此外，来自Carnegie Mellon、洛杉矶的加利福尼亚大学以及迈阿密大学等学者也做出了贡献Processing 的最初目标是开发图形的 sketchbook 和环境，用来形象地教授计算机科学的基础知识之后，它逐渐演变成了可用于创建图形可视化专业项目的一种环境如今，围绕它已经形成了一个专门的社区，致力于构建各种库以供用这种语言和环境进行动画、可视化、网络编程以及很多其他的应用Processing 是一个很棒的进行数据可视化的环境，具有简单的接口、功能强大的语言以及一套丰富的用于数据以及应用程序导出的机制Processing 运行于 GNU/Linux® 以及 Mac OS X 和 Windows® 上，并且支持将图像导出成各种格式对于动态应用程序，甚至可以将 Processing 应用程序作为 Java™ applet 导出以用在 Web 环境内 2 如何安装Processing配置Java环境，JDK包下载：http://java.sun.com，环境配置教程：http://wenku.baidu.com/view/a2e732caa1c7aa00b52acb9b.htmlProcessing最新版本下载地址：http://processing.org/download，解压文件，打开processing.exe即可开始使用Processing的工程也非常文艺地取名为“素描本”——SketchToolbar工具栏：运行和停止，模式选择：多种运行模式，默认为Java，还有Android和JavaScript等模式Console 控制台：黑色区域上方是信息区，运行时的PDE状态、出错信息等都会显示在这里，黑色区域是控制台 3 绘制基本图形1234567891011121314151617181920212223242526void setup()&#123; size(800, 300);//the size of the window // The upper left corner is (0, 0)&#125;void draw()&#123; background(200); fill(255); strokeWeight(1); // Stroke weight to 1 pixels line(0,100,80,200); fill(102); rect(100, 100, 100, 100);//draw a rectangle strokeWeight(4); // Stroke weight to 4 pixels //(0, 100) is the location of upper left point and (100, 100) is the lower right conner point fill(0,255,0);//green ellipse(300, 150, 100, 100);//draw a ellipse //160, 150 is the location of center, 260 and 20 represent width and height fill(0,0,255);//blue triangle(400,100,400,200,500,200); fill(0,0,255,100);//light blue, the forth parameter is transparency strokeWeight(8); // Stroke weight to 8 pixels smooth(); arc(600,150,100,100,QUARTER_PI, PI+HALF_PI);//clockwise, QUARTER_PI to PI+HALF_PI noSmooth(); fill(255,0,0);//red arc(750,150,100,100,radians(45),radians(360));&#125; 4 绘制复杂图形(1) 针和线1234567891011size(480, 120);background(0);fill(255);stroke(102);for (int y = 20; y &lt;= height-20; y += 10) &#123; for (int x = 20; x &lt;= width-20; x += 10) &#123; ellipse(x, y, 4, 4); // Draw a line to the center of the display line(x, y, 240, 60); &#125;&#125; (2) 响应鼠标12345678910void setup() &#123; size(480, 300); stroke(0, 102);&#125;void draw() &#123; float weight = dist(mouseX, mouseY, pmouseX, pmouseY); strokeWeight(weight); line(mouseX, mouseY, pmouseX, pmouseY);&#125; (3) 加载图片123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106//作者：鳥仟一·超傑 来源：知乎//链接：https://www.zhihu.com/question/27917305/answer/46652009PImage img;ArrayList &lt;Circle&gt; circles = new ArrayList &lt;Circle&gt; ();int shiftx, shifty;void setup()&#123; //noLoop(); colorMode(HSB); background(255); smooth(); noStroke(); img = loadImage(\"Apple_logo_black.jpg\"); //size((int (img.width*2), (int) (img.height*1.2)); size(1200, 800); shiftx = width/2-img.width/2; shifty = height/2-img.height/2; img.loadPixels(); //image(img,shiftx,shifty);&#125;void draw()&#123; //img.loadPixels(); background(255); //image(img,shiftx,shifty); if(circles.size()&gt;0)&#123; for(Circle c : circles)&#123; c.display(); &#125; &#125; float xn, yn; while(true)&#123; xn = (randomGaussian()*200)+mouseX; yn = (randomGaussian()*200)+mouseY; int xns,yns; xns = (int) (xn-shiftx); yns = (int) (yn-shifty); if (xns&lt;0 || xns&gt;=img.width || yns&lt;0 || yns&gt;=img.height) break; int loc = xns + yns*img.width; float b=brightness(img.pixels[loc]); if(b&gt;50)&#123; break; &#125; &#125; boolean sign = true; for(Circle c:circles)&#123; if(dist(xn,yn,c.x,c.y)&lt;c.r+2)&#123; sign = false; break; &#125; &#125; if(sign)&#123; Circle cir = new Circle(xn,yn); cir.grow(randomGaussian()*5+10); circles.add(cir); &#125;&#125;class Circle&#123; float x,y,r; color c; Circle(float xin, float yin)&#123; x = xin; y = yin; c = color(random(255),255,255); &#125; void display()&#123; noStroke(); fill(c); ellipse(x,y,2*r,2*r); &#125; void grow(float rmax)&#123; for(float ri=2; ri&lt;rmax; ri+=1)&#123; r = ri; boolean sign1 = false; for(Circle c : circles)&#123; if(dist(x,y,c.x,c.y) &lt;= c.r+r)&#123; sign1 = true; break; &#125; &#125; if(sign1)&#123; break; &#125; boolean sign2 = false; for(int i=0; i&lt;360; i++)&#123; float rad = radians(i); float xa = x+cos(rad)*r; float ya = y+sin(rad)*r; int xs = (int) (xa-shiftx); int ys = (int) (ya-shifty); if(xs&lt;0 || xs&gt;=img.width || ys&lt;0 || ys&gt;=img.height) break; int loc = (int) (xs+ys*img.width); float b = brightness(img.pixels[loc]); if(b&lt;50)&#123; sign2 = true; break; &#125; &#125; if(sign2)&#123; break; &#125; &#125; &#125;&#125;void mousePressed()&#123; save(\"apple2.png\");&#125; 写在后面Processing是我偶然看到城室科技 | CitoryTech的文章，文中作者提到的可视化软件通过查找相关资料，看到了Processing的功能特别适合算法可视化和交互设计就喜欢上了总而言之，Processing是一款有趣的可视化软件，轻编程重设计，很好很强大","comments":true,"tags":[{"name":"可视化","slug":"可视化","permalink":"http://yoursite.com/tags/可视化/"}]},{"title":"CFSFDP聚类算法","date":"2017-04-14T12:24:18.000Z","path":"2017/04/14/CFSFDP聚类算法/","text":"聚类分析又称聚类，是把一个数据集合划分为多个集群（cluster）的过程，使得相同集群内的数据之间具有相似性，不同集群的数据之间具有差异性。聚类是数据挖掘、统计分析的主要任务之一，应用于机器学习、模式识别、图像处理、信息检索、生物信息、数据压缩和计算机图像等领域。（From 维基百科） 1 聚类算法总结常用的聚类算法包括：（1）启发式分割算法：起始确定K个中心点，用距离公式来判断数据点归属，用代价函数（如最小化平方和）评价聚类结果，迭代直至最优，例如：K-Means，K-Medoids。（2）基于模型的算法：起始随机确定若干个模型中心，用基于概率的方法判断数据点归属，通过迭代的方法找寻适合各个类的模型，例如：Gaussian Mixture Model。（3）降维的方法：通过降维，找寻数据间的特征，再完成聚类，例如：Spectral Clustering，Normalised-Cut。（4）基于密度的方法：定义数据点密度，从少数对象开始拓展得到集群，例如：DBSCAN，CFSFDP。根据聚类的数据特征应合理选用聚类算法。如图1所示，包含球形集群和非球形集群两幅典型示意图，在球形集群中，数据集相对集中，且无空间分布规律特征，这时候常常采用K-means、K-medoids、Gaussian Mixture Model等方法来聚类。而对于非球形集群，数据点分布具有空间特征，图1（b）所示的是具有三个集群的数据集，三个集群的数据点分布呈现类渐开线特征，这时就不能采用传统的聚类方法，而应选择Spectral Clustering、Normalised-Cut、DBSCAN和CFSFDP等等。 图1 2 CFSFDP聚类算法CFSFDP算法即为Clustering by fast search and find of density peaks，这是由Alex Rodriguez 和Alessandro Laio于2014年发表在《Science》期刊的聚类算法。该算法的基本假设有两个，一是聚类中心附近的数据点具有较低的密度，而是数据点与其他密度更大的中心距离较远。数据点密度的定义为： $$\\rho_i=\\sum_j\\chi(d_{ij}-d_c)$$ 这里，当$x&gt;0$时，$\\chi(x)=1$，当$x&lt;0$时，$\\chi(x)=0$。其中，$d_c$为截断距离（Cutoff distance），即确定密度的重要阈值，文中提到$d_c$取合适值使得平均密度为总数据量的1%-2%。数据点与密度较大点间的最小距离定义为： $$\\delta_i=\\left\\{\\begin{aligned}\\min_{j:\\rho_j&gt;\\rho_i}(d_{ij}),\\quad if\\quad \\rho_i&lt;\\max\\{\\rho_i\\} \\\\\\max_j(d_{ij}),\\quad if\\quad\\rho_i=\\max\\{\\rho_i\\}\\end{aligned}\\right.$$ 在文中的例子中，数据集如图2（a）所示，分别计算出$\\delta$和$\\rho$，在所有的数据点中，有四种点，一是$\\delta$大$\\rho$大的点，包括1和10；二是$\\delta$大$\\rho$小的点，包括28，26，27；三是$\\delta$小$\\rho$大，包括7，8，3，4等等，四是$\\delta$小$\\rho$小，其余点都是这个类别。很明显，第一种点即为集群的中心，第二类则是离群点。文章中提到定义一个指标来选择中心，用$\\delta$和$\\rho$乘积的形式：$$\\gamma_i=\\delta_i\\cdot\\rho_i$$ 图2在确定数个中心之后，其余数据点按照密度大小，依次从属于距离最近的密度大于其自身的点。根据该聚类算法的步骤，我自己设计了类渐开线数据集的聚类实验，聚类结果如图3所示。图3（a）是K-means的聚类结果，很明显这种方法未能实现非球形聚集的聚类问题，而CFSFDP算法则能够实现目标。然而，在实验中发现参数$d_c$的选择很大程度上影响了实验结果，很难确定。 图3 3 阈值讨论——Data Field由于参数$d_c$是CFSFDP算法中重要的影响因素，因此其确定方法引起了一些学者的兴趣，其中有Wang等人提出了使用名为Data Filed的方法来确定。他们定义每个数据点的潜力（Pontential）为： $$\\phi_i=\\sum_{j=1}^n m_jK(\\frac{x_i-x_j}\\sigma)$$ 这里，而所以数据点潜力可组成的数据场（Data Filed），其范围由最小化的熵值H（Entropy）来确定，公式为： $$H=-\\sum_{i=1}^n\\frac{\\phi_i}{Z}\\ln{\\frac{\\phi_i}{Z}}$$ 求出数据点的潜力公式中的$\\sigma$从而确定空间中的数据场。他们比较了数据场的热力图和CFSFDP算法得到的聚类结果图，发现二者很相近，因此就认为$d_c$的确定可以由数据场的方法来实现。当潜力公示的核函数用高斯函数的时候，高斯函数具有“3$\\sigma$准则”，因此$d_c$的取为$\\frac{3}{\\sqrt{2}}\\sigma$，表示数据点的影响范围。这里的取值较为难理解，一般都是直接用均值$\\pm3\\sigma$的区间。然而，从他们的实验对比中，可以发现这种确定方法得到较好的聚类结果，相关成果发表的论文得到了84次的引用量。 4 改进策略1——借助Chameleon模型Zhang等人提出CFSFDP算法不适用与一些特殊的数据集，例如图4所示的数据集合。这个数据集其实是由三个数据集群组成的，外围集群、内左集群和内右集群，但是Zhang等人用CFSFDP算法来聚类，尝试用不同的$d_c$值，都难以得到好的聚类结果，如图5所示。因此，他们研究了改进的策略。 图4 图5Zhang等人的改进策略是受Chameleon模型启发，该模型的基本思想如图6所示，包括三个步骤，一是将数据集合用k近邻图的方法，组成稀疏图，而是将稀疏图打散分成若干个小类，三是重新组合，得到最后的聚类结果。 图6Chameleon算法定义了两个概念，相对互关联（Relative inner-connectivity）代表小类之间的连接区域强度的总和，相对紧密度（Relative closeness）则代表小类之间的连接区域强度的平均值。两个指标都有相应的公式，并进行标准化，然后结合两个指标来合并小类。借助这种思想，Zhang等人设置较小的$d_c$，然后用CFSFDP聚成数目较多的小类，之后再合并成集群，图7所示即为他们文中的实验。先讲两个U型集群组成的数据划分为若干个小类，再用Chameleon算法来合并小类，最终得到结果。 5 改进策略2——一些改进措施Gao等人在文章中总结了CFSFDP算法在实际应用中遇到的问题： 图7（1）截断距离dc需要依靠先验经验确定；（2）集群中心选择需要主观地从决策图中选择；（3）相同的高密度峰会算法会失效；（4）算法无法应用与特殊的数据集。 Gao等人在文中提出了改进的模型ICFS，模型的具体步骤如图8所示，分成：预聚类、合并、拆分三个阶段。 图8预聚类阶段，他们重新定义了$d_c$的确定公式、中心的选择方式和分配策略。其中，中心的选择方式是在原有算法利用$\\delta$和$\\rho$乘积的形式，将得到$\\gamma$值从大到小排列，然后分别再乘以密度$\\rho$，将新的决策图（decision graph）与原有的决策图对比，从新的$\\gamma^\\prime$值开始，第一次出现阶跃点（Bump point）的时候，即有$\\gamma_k^\\prime&gt;\\gamma_{k+1}^\\prime\\&amp;\\gamma_k^\\prime&gt;\\gamma_{k-1}^\\prime$，则将1到k所以数据点作为中心，这个过程如图9所示。 图9分配策略改变原有的“从属最近的较高密度点”分配，而是“使非中心点优先从属于最近的相同密度点”，如图10所示。然而这种分配方式也不完全合理，在对于相同密度的A和B，先分配A或者先分配B得到的结果是不同的。 图10完成预聚类之后，Gao等人也提出了类合并和拆分的策略，合并是根据最近邻图的方法，而拆分则是根据“同一类中不能同时含有两个阶跃点”的准则。 6 总结聚类算法在数据挖掘中是常用且重要的算法，但应用数据集特征不同，可能要先挑选合适的算法。CFSFDP算法是新颖的基于密度的聚类算法，给我们提供了一种新的聚类思路，方式具有普适性，得到不少学者的认可。然而，算法的本身的参数阈值确定和逻辑规则还有待改进。当然，改进算法也不是越复杂越好，太过于复杂的算法可能就会失去普适性，因此，改进策略需要在后续研究中进一步尝试。 参考文献[1] Alex Rodriguez and Alessandro Laio. Clustering by fast search and find of density peaks. Science 344, 1492 (2014).[2] Wang S, Wang D, Li C, et al. Comment on “Clustering by fast search and find of density peaks”. Computer Science, 2015.[3] Wang S, Wang D, Li C, et al. Clustering by fast search and find of density peaks with data field. Chinese Journal of Electronics, 2016, 25(3):1492-6.[4] Zhang W, Li J. Extended fast search clustering algorithm: widely density clusters, no density peaks. Computer Science, 2015.[5] Karypis G, Han E H, Kumar V. Chameleon: hierarchical clustering using dynamic modeling. Computer, 1999, 32(8):68-75.[6] Gao J, Zhao L, Chen Z, et al. ICFS: An improved fast search and find of density peaks clustering. 2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress. 2016:537-543.","comments":true,"tags":[{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://yoursite.com/tags/数据挖掘/"},{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"Python可视化入门","date":"2017-04-13T07:56:18.000Z","path":"2017/04/13/Python可视化入门/","text":"可视化路漫漫，一步一个脚印往前走！ 写在前面最近一直在可视化的道路上不断前行，看书+码代码一开始是看浙大陈为他们写的《数据可视化》，了解可视化的一些基本知识然后是看可视化工具，Python可视化只是其中之一本文是基于《Python数据可视化编程实战》内容总结的主要是关于Python可视化入门的基础内容，更多是以例子和程序来总结 S1 环境设置需要安装库：matplotlib、Numpy、Scipy、PIL、Requests可使用预打包环境：EPD、Anaconda、Python(x,y)1234567891011import matplotlib.pyplot as plt import numpy as np t = np.arange(0.0, 1.0, 0.01) s = np.sin(2 * np.pi * t) #设置线宽、线性和颜色 plt.plot(t,s,color = 'r',marker = \"+\",linewidth=1) c = np.cos(2 * np.pi * t) plt.rcParams['lines.linewidth'] = 3 #plt.rcdefaults() -- set defaults plt.plot(t,c) plt.show() S2 读取CSV文件常规做法：12345import csvwith open(filename,'r',encoding = 'utf-8') as f: reader = csv.reader(f) header = reader.__next__()#python 3.x要用__next__() data = [row for row in reader] 数据量大：123data = numpy.loadtxt('ch02-data.csv',dtype='|S',delimiter=',') for datarow in data: print(datarow) S3 读取Excel文件123456789101112import xlrd filename = 'ch02-data.xlsx' wb = xlrd.open_workbook(filename = filename) ws = wb.sheet_by_name('Sheet1') dataset = [] for r in range(ws.nrows): col = [] for c in range(ws.ncols): col.append(ws.cell(r,c).value) dataset.append(col) 1from pprint import pprint 1pprint(dataset) S4 时间序列绘制1234567891011121314151617181920from pylab import * import matplotlib as matplotlib import datetime fig = figure() ax = gca() # get current axis start = datetime.datetime(2013, 1, 1) # set some daterange stop = datetime.datetime(2013, 12, 31) delta = datetime.timedelta(days = 1) dates = mpl.dates.drange(start, stop, delta) # convert dates for matplotlib values = np.random.rand(len(dates)) # generate some random values ax = gca() ax.plot_date(dates, values, linestyle = '-', marker='') # create plot with dates date_format = mpl.dates.DateFormatter('%Y-%m-%d') #specify formater ax.xaxis.set_major_formatter(date_format) # apply formater # autoformat data labels # rotates labels by 30 degrees by default # use rotate param to specify different rotation degree # use bottom param to give more room to date labels fig.autofmt_xdate() show() S5 常规图表、多图排列绘制12345678910111213141516171819from matplotlib.pyplot import * x = [1,2,3,4] # some simple data y = [5,4,3,2] figure() # create new figure subplot(321) # divide subplots into 3×2 grid and select #1 plot(x, y) subplot(322) #select #2 bar(x, y) subplot(323) # horizontal bar-charts barh(x, y) subplot(324) bar(x, y) # create stacked bar bar-charts y1 = [7,8,5,3] bar(x, y1, bottom = y, color = 'r') # stacked bar bar-charts subplot(325) boxplot(x) # box plot subplot(326) scatter(x, y) # scatter plot show() S6 热力图绘制12345678910111213141516171819202122232425262728293031import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import ImageGrid from matplotlib.cbook import get_sample_data def get_demo_image(): f = get_sample_data(\"axes_grid/bivariate_normal.npy\", asfileobj = False) # z is a numpy array of 15×15 Z = np.load(f) return Z, (-3, 4, -4, 3) def get_grid(fig=None, layout=None, nrows_ncols=None): assert fig is not None assert layout is not None assert nrows_ncols is not None grid = ImageGrid(fig, layout, nrows_ncols = nrows_ncols, axes_pad=0.05, add_all=True, label_mode='L') return grid def load_images_to_grid(grid, Z, *images): min, max = Z.min(), Z.max() for i, image in enumerate(images): axes = grid[i] axes.imshow(image, origin = 'lower',vmin = min, vmax = max, interpolation = 'nearest') if __name__ == '__main__': fig = plt.figure(1, (8, 6)) grid = get_grid(fig, 111, (1,3)) Z, extent = get_demo_image() # Slice image image1 = Z image2 = Z[:, :10] image3 = Z[:, 10:] load_images_to_grid(grid, Z, image1, image2, image3) plt.draw() plt.show() S7 用PIL做图像处理（1）PIL坐标系统原点（0，0）位于左上角；（2）im=Image.open(filename)：打开一个文件，并把图像加载在im对象上；（3）im.crop(box)：裁剪左、上、右、下像素内图像，box=(0, 100, 100, 100)；（4）im.filter(filter)：图像滤波；（5）im.histogram()：图像像素值直方图列表，单通道256个，双通道768个；（6）im.resize(size, filter)：重新调整图像大小，并且使用滤波器重新采样，滤波器可选NEAREST、BILINEAR、BICUBIC和ANTIALIAS，默认值为NEAREST。（7）im.rotate(angle, filter)：逆时针方向旋转图像；（8）im.split()：分离图像波段，可用于分离RGB图像为3个单独波段；（9）ImageChops.duplicate(image)：拷贝图像；（10）ImageChops.invert(image)：反转图像；（11）ImageChops.difference(image1, image2)：验证图像是否相同； S8 火柴杆图绘制1234567891011121314151617181920212223import matplotlib.pyplot as plt import numpy as np # time domain x = np.linspace(0, 20, 50) # random function to simulate sampled signal y = np.sin(x+1)+np.cos(x**2) # here we can setup baseline position bottom = -0.1 # True -- hold current axes for further plotting # False -- clear and use new figure/plot hold = False # set label for legend label = \"delta\" markerline, stemlines, baseline = plt.stem(x,y,bottom=bottom, label=label,hold=hold) # we use setp() here to setup # multiple properties of lines generated by stem() plt.setp(markerline, color = 'red', marker = 'o') plt.setp(stemlines, color = 'blue', linestyle = ':') plt.setp(baseline, color = 'grey', linewidth =2, linestyle = '-') # draw a legend plt.legend() plt.show() 结语本文主要是关于Python常规作图的总结，主要用到的是matplotlib库Python可视化绘图虽然没有达到R语言的那种认可度，但个人认为还是略胜于matlab的在之后的学术研究、实践应用，可以考虑选择Python进行绘图","comments":true,"tags":[{"name":"可视化","slug":"可视化","permalink":"http://yoursite.com/tags/可视化/"},{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"心情 2017-4-10","date":"2017-04-10T01:44:43.000Z","path":"2017/04/10/心情-2017-4-10/","text":"人间最美四月天，不负春光与时行清明已过，四月天即将来临，夏天的脚步渐渐近了天气没有前几周那么冷，外套收起来，短袖开始登场了南方的四月天注定是潮湿的，梅雨天气，空气里都是水蒸气四月天的心情是躁动的，闲不住，静不得也许生活没有太多变化，变化的只是所思所想 这阵子一直在忙活的实验室搭建的事情差不多完事了组里现阶段主要的事情是动漫-脑波的项目，主要是脑波数据分析这两天要写一个AGV相关的专利，但无从下笔，很纠结上周把之前录用的论文材料准备好了，钱也交了，就等待上传终稿最近在看的可视化相关内容（PYthon/Html/JavaScript/Processing）光看书、看教程、看程序印象还不深，得实际结合项目做一做 查找专利的时候偶然发现在学校写的那个专利逾期快被驳回了可能是项目结束了，觉得这个专利也不一定非要授权了专利局总是抓着鸡毛蒜皮在给意见，看来非专业写手总会有问题另外，还留意了同期wx和zyn写的，哈哈，大家都差不多嘛论文都发了，专利却一直过不去，不是说国内专利水水的嘛 脑波项目基本上能够谈下来，主要是企业那边意愿还算比较强烈现阶段，主要的问题是要尽快做出个demo（算法研发+软件开发）脑波的检测硬件是个麻烦事，国内没有，国外的又不是太靠谱让我做脑波数据分析，首先就是要采得到数据才行，硬件很伤脑筋相关的SDK也是麻烦，现在公司都很聪明，不给买断，按月/年付费可能接下来二三个月都要折腾这个事情了 数据可视化方面之前一直在看看书，看看程序实现，但没有找到网上的好项目可视化这块目前定位还是应用层面的，如果要说学术线路，还需要多积累Python等工具绘制可视化图表绰绰有余，matplotlib库支持好多类型图表Processing是一个好玩的可视化软件，具有动画、交互，还支持硬件结合Html+JavaScript是开发B/S平台的工具，想了想，B/S还是比C/S靠谱些 深度学习平台的搭建在硬件上基本上差不多了，软件上张工说也装好了关于Linux的使用之前没有太多经验，所以用起来很不顺手，安装调试费时间深度学习算法之前看了关于DBN、CNN、RNN，基本算法是了解了也根据组里买的书系统学习了TensorFlow的使用，使用起来应该问题不大在深度学习平台上跑几个demo应该问题不大，主要是投入时间的问题不过作为几十万的设备，真正用起来很关键，而不是简单演示几个demo 昨天看到马老师写的一篇关于交通网络图像化，用CNN进行预测的论文前段时间也看到一位3系的老师，用OLS相关模型来做交通预测自己以前也有类似的想法，但种种原因未能落地写下来，很是遗憾学术圈子里可能经常会有这种事情吧，研究领域相近，谁先发表出来谁占优势关于生物进化论，达尔文和华莱士先后研究出来，后人往往只记住了达尔文但两位大师的谦逊的学术态度、高尚的人格和对科学的重视态度，令后人十分敬佩是啊，学术研究终究是为人类作贡献，同行之间惺惺相惜、相互促进才是应该的 这周把《人类简史》看完了，本来我一向不太爱看评史类作品的，但这本当下大热这本书结合了历史、人文、哲学、地理等知识，提到的一些观点和看法还是很有意思的书中把现在的人类精确定位为“智人”，智人距今大概只有数万年智人的社会充满想象和信任，国家/法律/宗教、市场/金融/资本主义等等都是想象出来的智人的发展充满着血腥和压迫，不仅是对其他动植物，也对自身农业社会、工业社会都是大谎言，在社会中每个人身份限定、工作限定，缺乏自由书中还提到了人工智能，既兴奋又担忧，当“超人类”出现，这世界会不会变了样？很难说 由于TeamViewe崩了，昨天在家登不上去，这篇心情是周一在办公室写的篇头的图案是“剪不断，理还乱”，体现了我目前的处境和心态，迷茫和纠结很多事情需要去做，很多事情需要好好做，很多事情不愿意但不得不去做人生活在这社会中，充满着依托和凭借，依赖于他人生活，很多事情并不自由现在的吃点苦，努力多做点事，多学点知识，多攒经验，一切的一切都是为了以后的更自由","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017-4-2","date":"2017-04-02T01:33:56.000Z","path":"2017/04/02/心情-2017-4-2/","text":"这两天的天气真是捉摸不定时而下雨时而闷热清明时节到了，处于季节更替当中明天回老家上山扫墓去 这周感觉总体下来比较懵，忙得懵组里因为动漫方案，着急在整理实验室学校那边易华录项目资料需要撰写其余闲暇时间学了点JS 最近一直在考虑做学术的问题读博是应好好做点学术的自己对那些学术大牛们充满敬仰希望自己也能通过慢慢学术积淀在学术道路上有所建树 目前国内整体社会风气比较浮躁市场经济发展至今资本唯上房产市场一直高涨潜心好好做事情的氛围比较差只希望未来几年自己能够不忘初心静心学习，提高自己","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017-3-26","date":"2017-03-26T02:21:07.000Z","path":"2017/03/26/心情-2017-3-26/","text":"生活是一个泛泛的概念，可以从几个层面去理解亲情、友情、爱情等复杂情感及其外在行为表现吃饭、睡觉、发呆等每日必修课忙忙碌碌地工作之余，看剧上网打游戏等休闲娱乐所有的所有都只是生活的一部分然而，工作是独立无二的地位，工作是体现个人价值的方式 “燕雀安知鸿鹄之志”“士不可以不弘毅，任重而道远”“僵卧孤村不自哀，尚思为国戍轮台”任何时候，任何处境，心中都需要有一个梦想有梦想，才能激励人不断向前 这周看了数据可视化相关的内容，发现这个领域理论远高于实践要想做出准确、科学、好看的图表，经验也很重要之前主看书，之后要结合实践因此打算从html+CSS，然后结合python可视化，搭建web可视化平台在当前阶段主要还是多学习，多记录，积攒知识 根据网上TensorFlow例子教程，又跑了跑用户输入的手写字实验实验虽然简单，但能跑通深度学习的流程，这就够了深度学习现在是火热行业，涉及大量前沿技术国内外大牛、专家太多，行业略有泡沫作为行业边缘，我还是持观望状态，目前不想靠它吃饭 年前投的数据驱动控制和学习系统（DDCLS’2017）的会议录取通知下来了这个会议可谓艰难，投稿时间和审稿时间一拖再拖，总算给了结果了时隔1年多，好歹又有了一篇paper，也不枉在这待的这段时间了做学术其实还是有间歇性比较合适，一直做很枯燥，隔太久就手生 最近身体感觉好弱，经常在生病吃药，长时间处于不好的状态以后要坚持多锻炼，平常还是要注意保暖和作息规律好久没打过球了，年纪小矫情觉得这辈子离不开篮球，想想真是可笑人想法会一变再变，没有什么东西是可靠的时间是一切不解最好的解释，看淡了就好 终于无话可说了……（撒手）","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"心情 2017.3.19","date":"2017-03-19T01:34:08.000Z","path":"2017/03/19/心情-2017-3-19/","text":"下雨天的天空朦胧的，分不清白天还是傍晚轻轻的雨滴打在脸上，打湿了衣裳，加快了行人的步伐周末的早上，一个人在家，可以想着很多事情周四晚上十点吃的烧烤严重破坏了肠胃的正常工作隐隐忍受着来自腹部的阵痛，警醒着不自律的不该 最近，事情好多，这样的，那样的实验室搭建设备的购买，一直很繁琐计算集群的调试，艰难地进行着深度学习+机器视觉，理论和例子，苦不堪言交通大数据平台，两周过后，尚无头绪数据可视化，学习计划任重而道远学术研究，论文撰写，哪来的时间和精力啊 其实深度学习，我自己并不是拒绝的上周快速看了TensorFlow的入门教程对深度学习有了更深了解，并很快上手跑了一些例子说到底，开源的深度学习框架无非是一些工具箱罢了组长的想法是一切为了展示，这点不敢苟同布置的任务，感觉好不容易，只能再说再说 可视化领域，对我来说是一个新的天地数据的展示，向来十分美妙，而我之前只是略懂皮毛用心看书，用心学习，想必会受益匪浅从理论层面开始，后期结合程序实现，系统掌握一些手段对于我以后开发大数据平台应该会有所帮助的 当有心要离开，可能就会千般万般给自己找这里不好的理由也行，工作就是这样子吧，永远不能让人有多喜欢我自己觉得自己是个爱抱怨的人，在改但又不好改个人的发展始终要以个人的努力为基础任凭风雨雷电，保持初心，一直往前走就好了 昨天看了一直没找时间看的《这个杀手不太冷》虽然没有想象中那么好看但是lyon简单的生活方式和简单的个人性格让人印象深刻不需要考虑太多，不需要忧愁未来过着自己熟悉的生活，简单而又美好女主的乱入，打乱了一切，在我现在看来，觉得并不是好事有了牵挂，有了羁绊，人就会变得脆弱很多了我想，也许我真是一个冷漠的人罢了-.-","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"TensorFlow学习日志","date":"2017-03-15T11:31:57.000Z","path":"2017/03/15/TensorFlow学习日志/","text":"写在前面经过前一两周调试、熟悉深度学习设备，再加上实验室的改造，硬件差不多完事了在骆炜和瑞宇相继离开之后，决定由我来搞深度学习，临阵磨刀，肯定先看书啊组长买回两本深度学习的典型框架的书，分别是关于TensorFlow 和 Caffe本着对Python的不离不弃（其实是不想从头去看C/C++），决定入手TensorFlow这本《TensorFlow实战》是2017年2月刚上市的，好评如潮，值得一看 TensorFlow简介TensorFlow是由Google公司开发的开源框架，提供实现机器学习算法接口TensroFlow是由Google Brain团队基于第一代分布式机器学习框架DistBelief（未开源）上开发的2015.11在Github上开源，2016.4补充分布式版本，2017.1发布1.0版本TensorFlow官网：www.tensorflow.orgGitHub: github.com/tensorflow/tensorflow模型仓库：github.com/tensorflow/models前端支持：Python、C++、Go、Java等后端支持：C++、CUDA适合众多异构系统：Android、iphone、普通CPU、大规模GPU封装算法：深度学习、线性回归、逻辑回归、随机森林TensorFlow特点之一是用数据流式图来规划计算流程，即计算图 Tensorflow安装1、安装Anaconda (www.continuum.io/downloads)，内含Python应用程序及大量实用Python库2、CPU/GPU版本的TensorFlow库安装，从Python官网https://pypi.python.org/pypi 找对应版本3、安装CUDA，从NVIDIA CUDA官网http://developer.nvidia.com/cuda-toolkit 下载4、从http://developer.nvidia.com/rdp/cudnn-download 下载cuDNN，解压后有3个文件&nbsp;&nbsp;&nbsp;(1) 将cudnn.h放入CUDA的tookit安装目录的include文件夹中&nbsp;&nbsp;&nbsp;(2) cudnn.dll放入bin文件夹中&nbsp;&nbsp;&nbsp;(3) cudnn.lib放入lib/x64文件夹中 使用TensorFlow-GPU版本运行的话，如果CUDA文件成功加载的话会有下面的提示： I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre am_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre am_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre am_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre am_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre am_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally ... 还有设备显卡信息，目前GPU计算大多要求CUDA计算能力在3.0以上，像一般PC上的渣渣显卡，就会报这样的错误（心酸）然后，程序就会切换到CPU里计算 name: NVS 315 major: 2 minor: 1 memoryClockRate (GHz) 1.046 pciBusID 0000:03:00.0 Total memory: 1.00GiB Free memory: 591.15MiB I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_untime\\gpu\\gpu_device.cc:906] DMA: 0 I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_untime\\gpu\\gpu_device.cc:916] 0: Y I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_untime\\gpu\\gpu_device.cc:948] Ignoring visible gpu device (device: 0, name: NVS 315, pci bus id: 0000:03:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0. ... TensorFlow实例 Softmax Regrssion 使用手写数字数据库（MNIST：Mixed National Institute of standards and Technology database）Softmax Regrssion实际上是感知器模型，线性分类器，对手写数字的分类效果精度大约在92%（具体程序参见https://github.com/peter-cai/TensorFlowInAction ，下同） AutoEncoder 图像分类重要概念之一是稀疏编码，对于16px*16px的图片，几乎所有图像碎片都可以用64种正交边组合这些组合的正交边可称为basis，通过不同的方式可以组合成不同的高阶特征，如人脸、汽车等等由basis可以组合器官再组合成人脸，可以组合成零部件再组合成汽车AutoEncoder，即自编码器，期望输入和输出是一致的，目标是用稀疏的高阶特征来重构自己AutoEncoder为了有效提取特征信息，可以加入限制：控制隐层节点数量、权重L1正则化、给数据加噪2007年，Hinton在Science上发表了关于Deep Belief Network（DBN，深度置信网络）有效解决“梯度弥散”问题DBN包含三个步骤：AutoEncoder的无监督训练；提取特征并初始化权重；用标注数据进行监督训练。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AutoEncoder模型结构&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_*手写数字图像重构训练数据和输出结果_ Multi-layer Perceptron Multi-layer Perceptron（MLP，多层感知器）也就是Back Propagation，是神经网络中应用最广泛的算法之一MLP采用误差反向传播来反馈调整连接权值，权重采用梯度下降法调整MLP常采用Sigmoi函数作为激励，使模型具有非线性映射能力，但层数多会出现“梯度弥散”现象ReLU函数是最近使用广泛的函数，特点：单侧抑制、相对宽阔便捷、稀疏激活性、反向传播不会出现“梯度弥散”现象MLP、CNN隐层可以使用ReLU，输出层用Sigmoid函数（接近概率输出分布），而RNN常用sigmoid和tanh函数理论上，隐层节点数足够多的MLP模型可以拟合任意非线性函数，且所需隐层总节点数随隐层增多而指数下降在MNIST数据分类实验中，MLP精度在98%左右 Convolutional Nerual Network Convolutional Nerual Network（CNN，卷积神经网络）是当前图像处理领域最受欢迎的算法之一（RNN用于自然语言处理，Word2Vec用于将自此转哈uwei计算机可理解的稠密向量Dense Vector）CNN基本思想源于1960年代提出的感受野（Receptive Field）理论，认为每一个视觉神经元只会处理一小块区域的视觉图像图像在空间上是有组织结构的，每一个像素和周围的像素点实际上是有紧密联系的CNN首个成功的多层训练网络结构是LeCun的LeNet5CNN优点：降低数据预处理要求；对图像的缩放、平移、旋转等畸变具有不变性；卷积权值共享、减少参数、降低复杂度CNN要点：局部连接（local connectivity）+权值共享（weight sharing）+池化（pooling）+降采样（down-sampling）CNN有更优秀的网络设计，即卷积网络对图像特征的提取和抽象能力；权值共享大大减少了参数数量，降低计算量，减轻过拟合卷积层：特征选取，参数少；全连接层：分类预测，参数多CNN的发展现在有两个方向：网络结构优化和网络深度增加在MNIST数据分类实验中，CNN精度在99.2%左右 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;全连接（左）与局部连接（右） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LeNet5结构示意图 TensorBoard TensorBoard是TensorFlow官方推出的可视化工具，展示模型训练过程的汇总数据（标量/图片/音频/计算图/数据分布/直方图/嵌入向量）TensorBoard是将计算过程中的数据汇总记录在日志文件中，然后解析数据生产可视化的web界面（目前仅支持Linux系统的Chrome） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TensorBoard界面 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;计算图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据可视化","comments":true,"tags":[]},{"title":"心情 2017.3.12","date":"2017-03-12T02:06:30.000Z","path":"2017/03/12/心情-2017-3-12/","text":"这周回家了，在家里用TeamViewer远程控制办公室PC更博客，很好用本应是阳春三月，但南方此时还略有不少寒意，冬天的影子挥之不去家里边临近的外面普莲路，间歇能听到马路上喧嚣的车流声窗外时常有儿童嬉戏、大人阔谈的嘈杂，还偶有装修工人的忙碌声家里边三人时而走动、谈笑、吃喝，保持着最家庭的生活方式，惬意啊逝者如斯夫，生命融于光阴，情趣在于点点滴滴 前几天，终于将犹豫许久的Kindle买回来了，与其等KP4，还不如早买多看点书一直在给自己暗示多看点书，但世间终究喧哗太多，难得保持几分安静书吧，良莠不齐，有益书、闲书，有专业书、非专业书，有小说、史论、方法书、鸡汤书等等看书当须博览，不能总以“有用论”来衡量，久了易疲倦，但也不能耽于“杂书”，损益费时感兴趣的书有，史书、传记、诗歌、经典著作、都市小说，可泛看专业的书有，机器学习、交通、信息、数据、金融，偶尔可挑几本精看腹有诗书气自华，多看书，养成习惯，裨益一生 组里买回曙光的服务器了，上周安装调试，各种忙碌瑞宇可能在这边没有太多时间了，剩下的摊子基本上还是由我来做的深度学习还是要多少涉猎的，有兴趣，组里也支持，之后当多用点心深度学习涉及理论和应用，数学知识和IT编程结合，有深度，慢慢来，有收获就行 这几天，思维又进入回忆模式，想起过去的点点滴滴，尤其是高中时候人总是容易忘记不光彩的事情，而记住光鲜亮丽的时刻不能沉溺于过去，而是要检点自己，告诫自己，还年轻，当努力最近看的《君子一诺》小说里的主角苏措的形象让人印象深刻 勤奋好学，图书馆里一坐一整天，喜欢看书，重视每一门课程自力更生，大学时候就靠自己打工（进实验室、接代码活）养活自己多才多艺，下围棋、弹钢琴、滑冰、码代码，样样精绝沉稳大气，不为小事扰乱心静，谦卑处事，以礼待人意志坚定，不管别人怎么评价，保持自己的初心，坚持做自己想成为的那种人 这也是我想要成为的那种人，目标不远大没关系，一步一步往积极方向走就好了 有人说，不要让自己活的太舒服，渐渐地，就失去拼搏的劲了要经常给自己点小暗示，也就是多定小目标，一个个去完成家是温暖的港湾，但只适合短憩，小帆船的大世界是外面无尽的大海任由海水波涛汹涌，天空风雨雷电，只要把持好舵，尽管扬帆起航看来写鸡汤，很多人都会嘛！不过，自己给自己熬的，更好喝，哈哈","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"关于Markdow","date":"2017-03-05T07:53:52.000Z","path":"2017/03/05/关于Markdow/","text":"将一些关于Markdown语法（包括sublime设置）记录下来，方便以后查阅。 1 sublime 编辑器配置（1）Package Control是一个开源的用于插件管理的插件，在为Sublime安装其他插件之前，需要安装它。它有两种安装方式Simple和Manual。此处我们选择simple方式来安装。 从菜单 View - Show Console 或者 ctrl + ~ 快捷键，调出 console。将以下 Python 代码粘贴进去并 enter 执行，不出意外即完成安装。以下提供 ST3 和 ST2 的安装代码： Sublime Text 3： import urllib.request,os,hashlib; h = ‘2915d1851351e5ee549c20394736b442’ + ‘8bc59f460fa1548d1514676163dafc88’; pf = ‘Package Control.sublime-package’; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( ‘http://packagecontrol.io/‘ + pf.replace(‘ ‘, ‘%20’)).read(); dh = hashlib.sha256(by).hexdigest(); print(‘Error validating download (got %s instead of %s), please try manual install’ % (dh, h)) if dh != h else open(os.path.join( ipp, pf), ‘wb’ ).write(by) Sublime Text 2： import urllib2,os,hashlib; h = ‘2915d1851351e5ee549c20394736b442’ + ‘8bc59f460fa1548d1514676163dafc88’; pf = ‘Package Control.sublime-package’; ipp = sublime.installed_packages_path(); os.makedirs( ipp ) if not os.path.exists(ipp) else None; urllib2.install_opener( urllib2.build_opener( urllib2.ProxyHandler()) ); by = urllib2.urlopen( ‘http://packagecontrol.io/‘ + pf.replace(‘ ‘, ‘%20’)).read(); dh = hashlib.sha256(by).hexdigest(); open( os.path.join( ipp, pf), ‘wb’ ).write(by) if dh == h else None; print(‘Error validating download (got %s instead of %s), please try manual install’ % (dh, h) if dh != h else ‘Please restart Sublime Text to finish installation’) 按下enter之后可以看见编辑器最下面有提示正在安装，安装成功后会弹出一个README的文档。此时我们调出Command Paletter（Ctrl+Shift+P），输入pci选择install package，enter后会加载repository中的插件。搜索需要的插件按enter，等待几分钟，插件就安装好了。 （2）安装可选插件再次按下ctrl+shift+P打开快速菜单，键入’pcip’,回车，等待数据更新，完成后会主动显示软件列表。 在里面输入以下软件名称并回车进行安装： Markdown Editing // Markdown编辑和语法高亮支持Markdown Preview// Markdown导出html预览支持快捷键：preference -&gt; package settings -&gt; markdown editing -&gt;settings user里面添加： [ { “keys”: [“alt+m”], “command”: “markdown_preview”, “args”: { “target”: “browser”} }] auto-save // 可自定义的自动保存功能 前两个是标准的markdown编辑与预览工具，第三个是实现实时预览的关键,耐心等待操作完成，之后关闭并重新打开Sublime Text 3。 2 Markdow 语法转自http://www.cnblogs.com/hnrainll/p/3514637.html 标题设置（让字体变大，和word的标题意思一样）在Markdown当中设置标题，有两种方式：第一种：通过在文字下方添加“=”和“-”，他们分别表示一级标题和二级标题。第二种：在文字开头加上 “#”，通过“#”数量表示几级标题。（一共只有1~6级标题，1级标题字体最大） 块注释（blockquote）第一种：通过在文字开头添加“&gt;”表示块注释(&gt;和文字之间添加五个blank时，块注释的文字会有变化) example example 第二种：tab键 + 4个空格 example 斜体将需要设置为_斜__体_的文字两端使用1个“*”或者“_”夹起来 粗体将需要设置为粗体的文字两端使用2个“*”或者“_”夹起来 无序列表在文字开头添加(_, +, and -)实现无序列表。但是要注意在(_, +, and -)和文字之间需要添加空格。（建议：一个文档中只是用一种无序列表的表示方式） 有序列表使用数字后面跟上句号。（还要有空格） 链接（Links）Markdown中有两种方式，实现链接，分别为内联方式和引用方式。内联方式：This is an [example link](http://example.com/).引用方式：I get 10 times more traffic from [Google][1] than from Yahoo or MSN. [1]: http://google.com/ &quot;Google&quot; 图片（Images）图片的处理方式和链接的处理方式，非常的类似。内联方式：![alt text](\\images\\profile\\.jpg)引用方式：![alt text][id] [id]: /path/to/img.jpg &quot;Title&quot; 代码（HTML中所谓的Code）实现方式有两种：第一种：简单文字出现一个代码框。使用&lt;blockquote&gt;。（不是单引号而是左上角的ESC下面~中的） 第二种：漂亮的代码框，还可以自动高亮 123456int i = 0;i = 1;for (int i = 0; i &lt; 100; i ++)&#123; printf(\"helo markdown!\\n\")&#125; 第三种：使用Tab和四个空格。 int i = 0; i = 1; for (int i = 0; i &lt; 100; i ++) { printf(&quot;helo markdown!\\n&quot;) } 脚注（footnote）实现方式如下：hello3hello^hello 下划线在空白行下方添加三条“-”横线。（前面讲过在文字下方添加“-”，实现的2级标题） 其他 尖括号 http://ibruce.info bu.ru@qq.com可指定编程语言, &lt;&gt;代表左右大括号&lt;% codeblock [title] [lang:language] [url] [link text] %&gt;code snippet&lt;% endcodeblock %&gt; 1234567891011121314注释: Html的注释# &lt;!-- 注释 --&gt;转义字符 Markdown中的转义字符为\\, 转义的有:\\\\ 反斜杠\\` 反引号\\* 星号\\_ 下划线\\&#123;\\&#125; 大括号\\[\\] 中括号\\(\\) 小括号\\# 井号\\+ 加号\\- 减号\\. 英文句号\\! 感叹号 3.https://www.baidu.com ↩","comments":true,"tags":[{"name":"转载","slug":"转载","permalink":"http://yoursite.com/tags/转载/"},{"name":"技术","slug":"技术","permalink":"http://yoursite.com/tags/技术/"}]},{"title":"心情 2017.3.5","date":"2017-03-05T05:43:57.000Z","path":"2017/03/05/心情-2017-3-5/","text":"好久没能静下来写篇日志，以往那些社交平台很少更新内容了自己一直也想好好经营一个博客，之前在CSDN也写过，但没坚持下来最近刚好看到鹅厂大神Litten的博客，很棒，故有心效仿之由于编程基础实在太弱，看了N多网上教程，才有现在的博客样子HEXO+Gitbub确实很方便，yilia的主题风格也很合我的审美，挺好的一个写字的地方 从学校出来到现在差不多一年整了吧，研究所职工应该不算白领吧，顶多是个高级打工仔关于算法、机器学习，看书看了一些，还有各种博客，论文也有，兴趣所在，看了还是能学到不少项目相关的资料找了很多，物流、agv、被动雷达、智慧医疗……做了跟前25年数量一样多的PPT，练出来了么？恐怕未必学术方面，投了一个自动化人办的数据驱动会议，至今没信，其他的也有一些思路，可能要抓紧整理一下目前问题有，杂事太多，不能专注，没有成就感 现在逐渐养成一些习惯，尽量过自己想过的那种生活，远离不良习惯吃饭都基本按时吃，不怎么喝饮料了，多吃蔬菜、水果作息最近一直在调整，减少“看心情”地熬夜，坚持早上七点起床（好吧，今天算是九点起的，周末嘛 = =）每天走路上下班，偶尔会跑步流汗减膘，买了对哑铃一直在练上肢力量，但打球少了一直想养成看书的习惯，但一年下来感觉还不到十本，好吧，也许kindle买回来就会多看了经常还是会看斗鱼直播，偶尔打打手机游戏，NBA还是一直在关注，娱乐爱好还是难以扔下这一年最棒的就是在扇贝上面的坚持了，不吹不夸，打卡424天 说说最近的一些事情吧昨天曙光工程师来安装深度学习设备，之后可能会花时间在调试、运行，另外可能会做一些可视化的东西今天鲁老师跟我聊关于搭建一个交通数据平台，包括从网上爬取数据、宏观路网分析、车路协同等研究年后组里会再有频繁的人员流动，不过整体发展应该会更清晰一点这是第二次周末没有回家，上次没回家直接做了个大决定 多做事，少说话多思考，少犯错多看书，少发呆 要做一个数据分析师，交通行业专家，既能写文章，又能搞应用，会理论，懂算法，能编程 路漫漫其修远兮，吾将上下而求索","comments":true,"tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"},{"name":"叙事","slug":"叙事","permalink":"http://yoursite.com/tags/叙事/"}]},{"title":"The Wicked Postman","date":"2017-03-03T01:08:46.000Z","path":"2017/03/03/The-Wicked-Postman/","text":"Reprinted from the _Stary Birds_ Why do you sit there on the floor so quiet and slient, tell me, mother dear?The rain is coming in through the open window, making you all wet, and you don’t mind it.Do you hear the going striking four? It is time for my brother to come home from schlool.What has happened to you that you look so strange? Haven’t you got a letter from father today?I saw the postman bringing letters in his bag for almost everybody in the town.Only, father’s letters he keeps to read himself. I am sure the postman is a wicked man.But don’t be unhappy about that, mother dear. Tomorrow is market day in the next village. You ask your maid to buy some pens and papers.I myself will write all father’s letters; you will not find a single mistake.But, mother, why do you smile? You don’t believe that I can write as nicely as father does!But I shall rule my paper carefully, and write all the letters beautifully big.When I finish my writing, do you think I shall be so foolish as father and drop it into the horrid postman’s bag?I shall bring it to you myself without waitting, and letter by letter help you to read my writing. I know the postman does not like to give you the really nice letters.","comments":true,"tags":[{"name":"转载","slug":"转载","permalink":"http://yoursite.com/tags/转载/"},{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"}]},{"title":"机器学习总结","date":"2017-03-02T14:09:40.000Z","path":"2017/03/02/机器学习总结/","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机器学习（Machine Learning，ML）是一门多领域交叉学科，涉及概率统计、非线性优化、信息论、人工智能、计算复杂性和控制论等多门学科。目的是用计算机模拟或实现人类的学习行为，随着经验积累自动提高性能。 1 机器学习算法1.1 问题分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据问题本身的特征来分类，机器学习问题可分为监督学习、无监督学习、半监督学习和强化学习。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;监督学习（Supervised Learning）的特点是训练数据是有标签的，即对于每个输入都有相对应的输出，算法的目的是训练出能反应输入与输出之间的映射关系的模型。对于输出值是离散的（有限个数），称之为分类问题（Classification Problem）；对于输出值是连续的，则称之为回归问题（Regression Problem）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相对应的，无监督学习（Unsupervised Learning）的训练数据是没有标签的，即没有确定的输出值，就需要根据数据提取特征，这类问题的算法包括关联规则和聚类算法等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;半监督学习（Semi-supervised Learning）是介于监督学习和非监督学习之间，即数据一部分有标签，一部分没有标签，算法一半是需要考虑利用少量的标注样本和大量的非标注样本来完成训练、回归或分类。常用算法包括自训练（Self-training）、直推学习（ Transductive Learning）、生成式模型（Generative Model）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除此了上述的三类之外，还有强化学习（Reinforcement Learning）这一新兴的分类。强化学习是从环境状态到行为映射的学习，通过反复与环境交互来改进策略，以使系统行为从环境中获得的累积奖赏值最大。强化学习现主要应用于智能控制及分析预测等领域。强化学习可以动态地调整参数，与监督学习的区别在于产生的动作和获得的奖赏没有明确的函数形式表示，只能采用试探的方式进行，如果某一动作获得的奖赏为正，则以后产生这一动作的趋势会增加，反之则会减弱。 1.2 算法分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在机器学习的算法较多， 按照功能分类太大体可分为回归（Regression）、分类（Classification）、聚类（Cluster）、维度约减（Dimensionality Reduction）四个类别。其中回归和分类问题虽然在定义上有区别（连续和离散），但在本质上是一样的，算法是可以通用的，因此把二者涉及的算法归在一起。具体划分情况为： （1） 回归和分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性回归（Linear Regression）：拟合自变量和因变量线性关系的统计分析方法，常用最小二乘法来求解参数。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多项式回归（Polynomial Regression）：自变量次数大于1，但具体的次数选择往往要依靠经验，次数太高容易过拟合。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;朴素贝叶斯（Native Bayes，NB）：由贝叶斯公式得到的分类器，通过计算后验概率来分类。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;逻辑斯蒂回归（Logistic Regression）：在线性回归的基础上应用逻辑函数，函数值位于0到1之间，二值分类以0.5为界限。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;支持向量机（Support Vector Machine，SVM）：在较长一段时间被誉为二值分类问题最佳的模型。通过核函数映射，将低维线性不可分的数据集映射到高维，使其线性可分，并使分类界面间隔最大。算法求解过程用到了二次规划、拉格朗日乘子法、KKT条件、对偶问题、SMO算法等。SVM算法善于处理小样本问题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K近邻（K-Nearest Neighbors，KNN）：基于实例的算法，通过距离公式来寻找相似样本来做回归预测，依赖于样本数据的质和量，算法很成熟但计算量较大，因此后来又提出了KD树的方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;决策树（Decision Trees，DT）：直观运用概率的图解方法，按特征来生成决策树，使目标期望达到最大，实际使用过程特征选择方式和决策树的修剪是关键。决策树算法包括迭代二叉树（Iterative Dichotomiser 3，ID3）、C4.5和CART（Classification And Regression Tree）等衍生算法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;神经网络（Neural Network，NN）：模仿人类大脑的神经突触结构，从而完成信息的传递处理，是目前最流行的机器学习算法之一。神经网络按照隐层数的多少可分为浅层学习和深层学习，浅层学习包括感知器（Perceptron）、多层感知器（Multi-Layer Perceptron，MLP）、反馈神经网络（Back Propagation Neural Network，BP-NN）、径向基函数神经网络（Radial Basis Function Neural Network，RBF-NN）、极限学习机（Extreme Learning Machine，ELM）等，深层学习包括深度置信网络（Deep Belief Nets，DBN）、循环神经网络（Recurrent Neural Network，RNN）、卷积神经网络（Convolutional Neural Network，CNN）等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在实际使用过程中，往往还使用模型融合算法(Ensemble Algorithms)，这类的算法包括：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bagging（Bootstrap aggregation）：每次从样本集随机采样来训练弱分类器，重复多次，最后用投票的方式（分类）或求均值（回归）得到最后结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随机森林（Random Forest）：随机构造很多的CART（由树组成森林），模型关键参数是树个数目和树节点输入特征的个数（总特征树的子集，随机选取），通过综合决策树的结果得到分类结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自适应提升方法（Adaptive Boosting）：采用赋权的方式，先设置初始权重，然后每个弱分类器训练完根据效果改变权重，训练失败的样本增加权重，最后综合多个弱分类器的结果得到强分类器。 （2） 聚类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在部分学者的观点来看，数据挖掘的核心就是聚类，聚类问题是典型的无监督学习，按一定的规则将类似的样本进行组合的方式。大量数据可先通过聚类划分不同的类别，然后再进行其他机器学习的处理。常用的聚类算法包括：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K均值聚类（K-Means Cluster）：随机选择K个样本作为类别中心，根据离中心的聚类确定各个样本的归属，然后通过迭代的方式不断更新类别中心，直至不变。K值大小的选取很关键。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;层次聚类法（Hierarchical Cluster）：由起初的所有样本各自归为一类，根据样本间的聚类合并类并重新计算样本中心，迭代进行直至中心间距离大于限定阈值或达到限定的类别个数。每次迭代要计算两两间距，计算量较大。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;期望最大算法（Expectation Maximization ，EM）：迭代分成E步和M步，用于含有隐变量（Hidden Variable）的概率模型参数的极大后验概率估计。典型的应用是高斯混合模型（Gaussian Mixture Model，GMM），随机选择初始中心，按所属各个分布的概率大小进行分类。 （3） 维度约减&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度约减，即降维，是特征提前的过程，对于特征数特别多的数据集往往需要提取主要的特征，剔除次要特征，将数据集由高维映射到低维。主要的算法包括：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主成分分析（Principal Component Analysis，PCA）：数学基础是特征值分析，根据协方差矩阵求特征值和特征向量，按特征值大小依次选择特征向量构成特征矩阵。主成分分析得先做数据中心化。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;奇异值分解（Singular Value Decomposition，SVD）：将原始矩阵X分解成三个矩阵相乘，前后是正交非方阵，中间的是XTX的特征值平方根构成的对角阵，然后也是按特征值大小来选取特征。SVD其实算是PCA的一种处理方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏最小二乘法（partial least squares method，PLS）：偏最小二乘是多种方法的结合，包括多元线性回归、典型相关分析和主成份分析。在主成份分析中所选取的变量都是独立的，在特征之间的相关性较大的时候容易漏掉关键特征，而偏最小二乘可以避免这个问题。 1.3 学习策略（1）批量学习（Batch Learning）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（a）样本全部同时进入模型；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（b）梯度下降的方法容易陷入局部最优；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（c）学习并行性，速度快，但耗费存储量大。 （2）在线学习（Online Learning）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（a）样本按顺序进入模型，不断修正模型参数；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（b）随机性强，不容易陷入局部最优；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（c）学习串行性，需要依次迭代速度慢，但耗费存储量小。 2 模型选择2.1 基础知识&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;系统识别主要是要解决两个问题:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（1）建模描述系统输入与输出的函数映射关系；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（2）确定模型参数。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建模过程考虑的几个重要因素：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（1）泛化能力：对未知空间的预测能力，衡量模型优劣的主要指标；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（2）解释能力：建模是用数学的方法来解释现实问题，目的是通过模型找寻实际问题的最佳解决措施。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（3）维数灾难：模型可能涉及到很多的参数是无法通过样本来准确估计的，或者由于过多的参数而导致模型的泛化能力变差。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（4）计算能力：通常，随着模型的复杂度增加，所带来的计算复杂度也会倍增，甚至是指数性增加。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（5）输入选择：对于模型输入的变量并不是越多越好，如果输入中含有的无效成分太多，反而会影响最终输出结果。因此，要合理选择模型输入。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（6）鲁棒性和抗扰性：传统的线性系统常常是建立在带有高斯噪音的线性时不变过程。而实际动态的过程往往是复杂、非线性、非平稳、随机且部分未知的，因此保证模型的鲁棒性和抗干扰性是一大难题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（7）在线更新：对于持续输入样本的模型，不仅要实现参数实时更新，也要实现模型结构的自适应调整。 2.2 “过拟合”&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在过去，机器学习的目标往往是关注经验风险最小化（Empirical Risk Minimization，ERM），即以训练样本误差最小化来衡量模型的好坏，从而无限增加模型的复杂度。然而随着模型复杂度增加，模型的泛化能力反而会下降，即出现了“过拟合”现象，而提高泛化能力要综合考虑模型的偏差（Bias）和方差（Variance）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以均方误差来（Mean Square error，MSE）来衡量模型的泛化误差的话，对于$Y=f(x)+e$，$e$是$N(0,\\sigma_e)$分布的噪声干扰（白噪声），则模型在 处的泛化误差为： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图1所示，随着模型的复杂度增加，虽然偏差会不断减小，但方差先减小后增大，模型的泛化误差也是先减小后增大，因此需要在“欠拟合”和“过拟合”之间寻找合适的模型复杂度。衡量模型的复杂度通常有AIC准则（Akalike Information Criterion）、BIC准则（Bayesian Information Criterion）等方法。 图1 （1）赤池信息量准则（Akalike Information Criterion，AIC准则）$$AIC=-2ln L+2d$$其中，L是样本训练误差的极大似然值，假设误差服从正态分布，则误差越小，L越大，d是模型参数个数。AIC越小，则模型越好，即在保证参数个数少的情况下达到误差最小。 （2）贝叶斯信息量准则（Bayesian Information Criterion，BIC准则）$$ BIC=-2ln L+2d\\ln n $$这是基于贝叶斯角度考虑的推论，但实际上其与AIC准则表达式类似，也是越小越好。 2.3 正则化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在满足一定训练精度要求的情况下，倾向于选择、稀疏的模型结构来避免“过拟合”，这就是奥卡姆剃刀定律（Occam’s Razor）：“如无必要，勿增实体” （Entities should not be multiplied unnecessarily），即用简单有效的方法完成要求做的事。在机器学习中，控制模型复杂度典型方法是采用正则化。正则化的思想是结构风险最小化（Structural Risk Minimization，SRM）策略，在经验风险上加一个正则化项（Regularizer）或罚项（Penalty term）。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率，模型越复杂则先验概率概率越大，结构风险也就越大。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正则化方法有L0阶、L1阶和L2阶范数三种，其中L0阶范数的求解是NP难问题，较少采用；L1阶范数又称LASSO（least absolute shrinkage and selection operator），作用是特征选择；L2阶范数又称岭回归（ridge regression），作用是权值衰减。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在实际应用中，岭回归是保证回归矩阵权值的平方和尽可能小，无法产生稀疏化的回归矩阵和起到选择重要参数的目的，但在样本数较多的情况下，岭回归的精度高于LASSO。介于L1阶和L2阶范数之间还有elastic net方法，此时代价函数为：$$L(\\lambda_1,\\lambda_2,\\beta)=\\left|y-X\\beta\\right|^2+\\lambda_1\\left|\\beta\\right|_1+\\lambda_2\\left|\\beta\\right|^2$$这里，式子右边的第二、三项分别对应L1阶和L2阶范数。如果用形象化方式表达三者的关系，如图2所示。LASSO的特征选择方式的几何解释可以参考修正的最小角回归（Least Angle Regression）算法。由最残差相关系数最大的方向出发，随着前进步长增大，最优方向与残差的相关系数变小，直至找到次优参数方向，参数依次进入模型 图2 2 优化算法2.1 优化问题分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（1）一维搜索：求目标函数在直线上的极小点，称为一维搜索，或称为线搜索。一维搜索可归结为单变量函数的极小化问题。一维搜索包括试探法和函数逼近法。试探法：针对单峰函数，包括0.618法（黄金分割法）和Fibonacci法等；函数逼近法（插值法）：牛顿法、割线法和抛物线法等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（2）无约束问题优化法：目标问题没有约束条件，包括最速下降法、牛顿法、共轭梯度法、拟牛顿法等求解方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（3）约束问题优化法：目标问题有约束条件，包括可行方向法（Zoutendijk法）、惩罚函数法、乘子法、序列二次规划法等求解方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（4）整数规划：目标函数和约束函数是线性函数，还要求决策变量取整数值，包括分支定界法、割平面法等求解方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（5）动态规划：解决多阶段决策过程最优化的一种数学方法，主要用于以时间或地域划分阶段的动态过程的最优化。动态规划的经典问题是最短路问题和生成贮存问题。求解方法包括逆推法和顺推法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（6）最优性原理：作为整个过程的最优策略具有这样的性质：无论初始状态和初始决策如何，对前面的决策所形成的状态而言，余下的诸决策必须构成最优策略。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（7）多目标规划：目标函数含有多个子目标，互相之间可能是相互矛盾的，在这多个子目标之间进行协调和权衡，使各个子目标尽可能地达到理想值。对于多个目标可以采用加权等方式整合成单目标，也可以通过重要性排序等方式依次确定各个目标的最优，常用解法是遗传算法（GA）。 2.2 典型优化算法（1）遗传算法（Genetic Algorithm，GA）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;遗传算法是人工智能算法的重要分支，原理是模拟生物进化论和遗传学机理的生物进化过程的计算模型，包含了“适者生存”、“优胜劣汰”等规则。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;遗传算法包含遗传、变异和选择三个流程。个体编码常用无符号的二进制整数来表示。具体步骤包括：构造一定规模的初始种群，计算适应度决定遗传的概率，遗传运算（常用轮盘赌法），交叉运算（按概率发生片段交换）、变异运算（较小概率随机发生突变，防止陷入局部最优）。 （2）模拟退火算法（Simulated Annealing Algorithm，SA或SAA）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模拟退火算法源于固体退火原理，基于蒙特卡洛（Monte Calro）法迭代求解测量的一种随机寻优的算法。在某一初温下，伴随温度不断下降，结合概率突跳特性在解空间中随机寻找目标函数的全局最优解。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模拟退火包括加温、等温和冷却（退火）过程。设定初始值，进行蒙特卡洛模拟新状态，优化状态完全接受，也以一定概率接受劣化状态（防止局部最优），直到得到满足要求的解。这种方法本质还是随机求解法，计算量大，时间长。 （3）蚁群算法（Ant Colny Optimization，ACO）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;蚁群算法是一种用来在图中寻找优化路径的几率型算法，源于蚂蚁在寻找食物过程发现最优路径的行为。典型的应用是用于解决旅行商问题（Traveling salesman problem, TSP）。算法的一般步骤：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（a）初始化参数：开始时每条边的信息素量都相等；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（b）将各只蚂蚁随机放置各个顶点；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（c）依次选取蚂蚁周游所有顶点，计算转移概率（由每条边的信息素和启发因子决定，启发因子为路阻的倒数），以轮盘赌法决定下一个顶点，计算蚂蚁留在各边的信息素，更新信息素表。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（d）计算各边的信息素增量，记录本次迭代的路径，更新当前最优路径，清空信息素表。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（e）迭代运行，终止条件：最大迭代次数或停滞现象。 （4）粒子群算法（Particle Swarm Optimization，PSO）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;粒子群算法源于对鸟群捕食行为的研究，求解过程是从随机解出发，通过迭代寻找最优解，通过适应度评价解的品质。粒子群算法的一般过程：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（a）随机初始化一组微粒（问题可行解），包括随机位置和速度；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（b）评价每个微粒的适应度；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（c）根据个体极值和群体极值来更新当前位置。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（d）重复（b）和（c），记录下每个微粒每次迭代的位置和适应度，直至找到最优解。","comments":true,"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]}]